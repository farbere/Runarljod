{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e70c6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea2ce7",
   "metadata": {},
   "source": [
    "<h3>Keras models and training</h3>\n",
    "\n",
    "API documentation homepage: https://www.tensorflow.org/api_docs/python/tf?hl=en\n",
    "\n",
    "Intro to Keras tutorial: https://www.tensorflow.org/tutorials/keras/classification (with 'fashion MNIST' below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eddadaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "494883e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fashion_train_images, fashion_train_labels), (fashion_test_images, fashion_test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d241e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d4b6d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_train_images = fashion_train_images/255\n",
    "fashion_test_images = fashion_test_images/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ee8bda",
   "metadata": {},
   "source": [
    "The following constructs a feed-forward ('sequential') network with some specified layers. Keras' Dense layer is a fully-connected layer; that is, each of its units (neurons) sees every output from the previous layer.\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense?hl=en\n",
    "\n",
    "ReLU is probably the most popular activation function at this time, and there may be some theoretical reasons supporting this. tanh is another option; it's simply the logistic function (Keras: 'sigmoid') with its values symmetrised, so that tanh(x) lies between -1 and 1, and tanh(0) = 0. There are others that have been used. If the layer is not given an activation argument, then its output is simply a linear transformation of its inputs (that is, the activation function is the identity f(x) = x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7500f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Flatten(input_shape = (28,28)),  # Dense expects 1D input\n",
    "                            tf.keras.layers.Dense(128, activation='relu'), \n",
    "                            tf.keras.layers.Dense(10),\n",
    "                            tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98f168f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to leave out the Softmax layer above, add argument from_logits=True to the loss function here. I don't know\n",
    "# whether it makes any difference.\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2467b89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4972 - accuracy: 0.8250\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3709 - accuracy: 0.8668\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3336 - accuracy: 0.8775\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3101 - accuracy: 0.8868\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2926 - accuracy: 0.8917\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2780 - accuracy: 0.8969\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2646 - accuracy: 0.9013\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2522 - accuracy: 0.9062\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2460 - accuracy: 0.9090\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2340 - accuracy: 0.9124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c736846370>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the default batch_size is 32\n",
    "model.fit(fashion_train_images, fashion_train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06807312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.3370 - accuracy: 0.8834 - 412ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# score the model on the held-out set\n",
    "test_loss, test_acc = model.evaluate(fashion_test_images,  fashion_test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66342411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 808us/step\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(fashion_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75699314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to take a closer look...\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df['choice'] = pred_df.apply(np.argmax, axis=1)\n",
    "pred_df['real'] = fashion_test_labels\n",
    "errors = pred_df.loc[pred_df.choice != pred_df.real]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffdc957",
   "metadata": {},
   "source": [
    "The next few cells are some plotting routines from the tutorial to visualise some of the results given by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb8a6ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  true_label, img = true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  true_label = true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,13):\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    plot_image(i, predictions[i], fashion_test_labels, fashion_test_images)\n",
    "    plt.subplot(1,2,2)\n",
    "    plot_value_array(i, predictions[i],  fashion_test_labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d43ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions[i], fashion_test_labels, fashion_test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions[i], fashion_test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d045bec9",
   "metadata": {},
   "source": [
    "<h3>Keras Hyperparameters Tuner</h3>\n",
    "\n",
    "With a vast number of possible model configurations and hyperparameters it can be tedious and discouraging to try to explore the permutations manually. KerasTuner takes in a recipe, with specified variables, for making a model and tries out variations. \n",
    "\n",
    "The recipe is given a Hyperparameters object, which contains various methods that tell the tuner what data type and allowed values a given variable has. In the example below, the hp.Int() method creates an integer variable ranging from 32 to 512 in steps of 32. The method hp.Choice() can be used for categorical choices or numerical choices with irregular spacing. It simply takes in a list of allowed values from which the tuner will choose. There are a few more such methods. The first argument to each of these methods is a string giving the name the variable will get when the tuner makes its reports.\n",
    "\n",
    "KerasTuner API: https://keras.io/api/keras_tuner/\n",
    "KerasTuner tutorial: https://www.tensorflow.org/tutorials/keras/keras_tuner?hl=en (again with 'fashion MNIST' below)\n",
    "\n",
    "Hyperparameters doc: https://keras.io/api/keras_tuner/hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3262b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "489a40e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(tf.keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed30aa4",
   "metadata": {},
   "source": [
    "KerasTuner has a few discrete search routines to explore the hyperparameter space you defined: random search, Bayesian optimisation, and an algorithm called Hyperbandit. The tutorial uses Hyperbandit.\n",
    "\n",
    "The arguments <i>directory</i> and <i>project_name</i> below will save everything the model does to disk. They can be omitted. As a caution, the saved data may take up a lot of space as the size of the NN tested grows. I assume this happens because it's saving network weights to disk, but I haven't been able to figure out how to retrieve them. It probably does not matter.\n",
    "\n",
    "Tuner docs: https://keras.io/api/keras_tuner/tuners/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30182f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8eb709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef87a45",
   "metadata": {},
   "source": [
    "Here is a <b>warning</b>: the tutorial (on the webpage) passes an argument <i>validation_split</i> to the tuner search below. One may suppose this means the tuner will make a split of the data given to it. It does <i>not</i> do so; it appears that actually the keyword is undefined here. By default the tuner simply uses the training data given to it to compute its \"validation\" statistics. The correct way to specify validation data for the search is to pass a pair\n",
    "\n",
    "    validation_data = (val_features, val_labels)\n",
    "    \n",
    "In this example we'll just use the test set already provided. As a reminder, for real applications we must make a split within the training data for this. The alternative is to invite overfitting hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b436a3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 31s]\n",
      "val_accuracy: 0.8830999732017517\n",
      "\n",
      "Best val_accuracy So Far: 0.8830999732017517\n",
      "Total elapsed time: 00h 07m 05s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# the callback here will automatically end the search if its condition is met, that a model does not improve its loss\n",
    "# on the validation set after a set number of training epochs. You can also end it mid-search by interrupting the python \n",
    "# kernel; it retains the results up to that time.\n",
    "tuner.search(fashion_train_images, fashion_train_labels, \n",
    "             validation_data = (fashion_test_images, fashion_test_labels), \n",
    "             callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e9216a",
   "metadata": {},
   "source": [
    "Passing an integer to the Tuner method .get_best_hyperparameters() will give you that many of the top results encountered during the search. For the Bayes search this does not appear to be helpful. This is because essentially it tries to fine-tune the hyperparameters by looking at a lot of models around where it gets good results. Consequently, the top entries of this list may be very close or even identical. Hyperbandit is slightly better in this regard, since its algorithm also tries to explore new parts of the hyperparameter space.\n",
    "\n",
    "In any case, the method .results_summary() will print a bunch of the top models. This summary also includes their scores on the search objective (here, <i>val_accuracy</i>).\n",
    "\n",
    "Of course, there is no guarantee that the search will actually find any or all of the \"best\" models. More, the result of training them depends on their random weight initialisation. The tuner just tries things and reports on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c50a870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters()[0]\n",
    "# tuner.get_best_hyperparameters()[0].values gives you the underlying dict, with keys the variable names you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c379001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 160 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eda6efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5144 - accuracy: 0.8209 - val_loss: 0.4043 - val_accuracy: 0.8538\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3835 - accuracy: 0.8621 - val_loss: 0.3673 - val_accuracy: 0.8690\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3439 - accuracy: 0.8739 - val_loss: 0.3462 - val_accuracy: 0.8768\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3146 - accuracy: 0.8823 - val_loss: 0.3354 - val_accuracy: 0.8813\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2954 - accuracy: 0.8907 - val_loss: 0.3326 - val_accuracy: 0.8819\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2821 - accuracy: 0.8963 - val_loss: 0.3444 - val_accuracy: 0.8775\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2710 - accuracy: 0.8989 - val_loss: 0.3356 - val_accuracy: 0.8802\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2582 - accuracy: 0.9037 - val_loss: 0.3222 - val_accuracy: 0.8852\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2450 - accuracy: 0.9085 - val_loss: 0.3215 - val_accuracy: 0.8827\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2365 - accuracy: 0.9125 - val_loss: 0.3182 - val_accuracy: 0.8885\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2295 - accuracy: 0.9144 - val_loss: 0.3195 - val_accuracy: 0.8900\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2232 - accuracy: 0.9152 - val_loss: 0.3191 - val_accuracy: 0.8913\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2111 - accuracy: 0.9199 - val_loss: 0.3317 - val_accuracy: 0.8878\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2083 - accuracy: 0.9213 - val_loss: 0.3287 - val_accuracy: 0.8901\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1999 - accuracy: 0.9250 - val_loss: 0.3435 - val_accuracy: 0.8900\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1927 - accuracy: 0.9279 - val_loss: 0.3378 - val_accuracy: 0.8913\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1890 - accuracy: 0.9295 - val_loss: 0.3161 - val_accuracy: 0.8932\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1832 - accuracy: 0.9302 - val_loss: 0.3333 - val_accuracy: 0.8940\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1778 - accuracy: 0.9330 - val_loss: 0.3249 - val_accuracy: 0.8947\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1713 - accuracy: 0.9348 - val_loss: 0.3511 - val_accuracy: 0.8888\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1669 - accuracy: 0.9370 - val_loss: 0.3359 - val_accuracy: 0.8942\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1630 - accuracy: 0.9388 - val_loss: 0.3463 - val_accuracy: 0.8961\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1608 - accuracy: 0.9397 - val_loss: 0.3692 - val_accuracy: 0.8913\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1550 - accuracy: 0.9413 - val_loss: 0.3846 - val_accuracy: 0.8834\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1512 - accuracy: 0.9439 - val_loss: 0.3720 - val_accuracy: 0.8907\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1472 - accuracy: 0.9449 - val_loss: 0.3820 - val_accuracy: 0.8906\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1438 - accuracy: 0.9451 - val_loss: 0.3885 - val_accuracy: 0.8890\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1398 - accuracy: 0.9479 - val_loss: 0.3633 - val_accuracy: 0.8951\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1361 - accuracy: 0.9486 - val_loss: 0.3888 - val_accuracy: 0.8942\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1325 - accuracy: 0.9503 - val_loss: 0.3852 - val_accuracy: 0.8930\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1286 - accuracy: 0.9514 - val_loss: 0.3903 - val_accuracy: 0.8915\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1303 - accuracy: 0.9515 - val_loss: 0.3786 - val_accuracy: 0.8955\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1263 - accuracy: 0.9528 - val_loss: 0.3939 - val_accuracy: 0.8945\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1218 - accuracy: 0.9545 - val_loss: 0.4171 - val_accuracy: 0.8914\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1190 - accuracy: 0.9556 - val_loss: 0.4539 - val_accuracy: 0.8823\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1153 - accuracy: 0.9566 - val_loss: 0.4123 - val_accuracy: 0.8919\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1148 - accuracy: 0.9569 - val_loss: 0.4251 - val_accuracy: 0.8867\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1122 - accuracy: 0.9584 - val_loss: 0.4396 - val_accuracy: 0.8918\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1086 - accuracy: 0.9587 - val_loss: 0.4181 - val_accuracy: 0.8951\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1086 - accuracy: 0.9591 - val_loss: 0.4462 - val_accuracy: 0.8917\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1037 - accuracy: 0.9610 - val_loss: 0.4381 - val_accuracy: 0.8917\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1027 - accuracy: 0.9612 - val_loss: 0.4397 - val_accuracy: 0.8903\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1016 - accuracy: 0.9625 - val_loss: 0.4333 - val_accuracy: 0.8911\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0990 - accuracy: 0.9629 - val_loss: 0.4804 - val_accuracy: 0.8885\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0962 - accuracy: 0.9634 - val_loss: 0.4547 - val_accuracy: 0.8947\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0929 - accuracy: 0.9647 - val_loss: 0.4672 - val_accuracy: 0.8908\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0943 - accuracy: 0.9645 - val_loss: 0.4759 - val_accuracy: 0.8900\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0915 - accuracy: 0.9651 - val_loss: 0.4902 - val_accuracy: 0.8888\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0882 - accuracy: 0.9672 - val_loss: 0.4805 - val_accuracy: 0.8944\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0886 - accuracy: 0.9674 - val_loss: 0.5000 - val_accuracy: 0.8912\n"
     ]
    }
   ],
   "source": [
    "# For the model method .fit() the validation_split argument does what it's supposed to.\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(fashion_train_images, fashion_train_labels, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ab9391e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 22\n"
     ]
    }
   ],
   "source": [
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fede134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can fill up the screen with output doing this and find similar results\n",
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "hypermodel.fit(fashion_train_images, fashion_train_labels, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7a22e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.5449 - accuracy: 0.8864 - 404ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# after using a subset of the training data to try to compare and optimise hyperparameter choices, there is the 'original' \n",
    "# test set to validate, or not, the results.\n",
    "test_loss, test_acc = model.evaluate(fashion_test_images, fashion_test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1819ee68",
   "metadata": {},
   "source": [
    "<h3>Model testing: Convolution blocks and regularisation methods</h3>\n",
    "\n",
    "Below: trying out the API etc with the garg data set.\n",
    "\n",
    "Convolution layer docs: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D?hl=en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef79503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_garg = pd.read_csv(\"sign_mnist_train.csv\")\n",
    "test_garg = pd.read_csv(\"sign_mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53209966",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_garg_square = train_garg.drop('label',axis=1).to_numpy().reshape((27455, 28, 28))\n",
    "test_garg_square = test_garg.drop('label',axis=1).to_numpy().reshape((7172,28,28))\n",
    "\n",
    "train_garg_square = np.float32(train_garg_square) / 255\n",
    "test_garg_square = np.float32(test_garg_square) / 255\n",
    "\n",
    "train_garg_labels = train_garg['label'].to_numpy()\n",
    "test_garg_labels = test_garg['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2d1ea5",
   "metadata": {},
   "source": [
    "The Hyperparameters method .conditional_scope() allows parts of the recipe to depend on earlier choices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5edbfe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model_builder(hp):\n",
    "    f_min, f_max, f_step = 8, 128, 8\n",
    "    layers_min, layers_max = 1, 4\n",
    "     \n",
    "    hp_filters = []\n",
    "    hp_rec_fields = []\n",
    "    hp_padding = []\n",
    "    hp_use_bias = []\n",
    "    hp_layers = hp.Int('conv_layers', min_value = layers_min, max_value = layers_max)\n",
    "    \n",
    "    model = tf.keras.Sequential()          \n",
    "    for i in range(0, hp_layers):\n",
    "        \"\"\" \n",
    "    I think the intended correct way to do this is to have the following in a code block starting\n",
    "        with hp.conditional_scope('conv_layers', list(range(0, hp_layers))):\n",
    "    but that raises an exception: \n",
    "        NotImplementedError:\n",
    "        Lists of stacks of conditions used during `explore_space()`.\n",
    "    Without conditional_scope when hp_layers < layers_max the tuner still chooses values for the variables in the \n",
    "    iterations of this loop that aren't triggered (it doesn't display them during the search process, but see the model\n",
    "    in the results_summary below with score 0.6954), and consequently treats as different instances of the same model. \n",
    "    Aside from being a waste of time, this may not interact well with the Hyperbandit algorithm.\n",
    "    \"\"\"\n",
    "        hp_filters.append(hp.Int('conv_filters_' + str(i), min_value = f_min, max_value = f_max, step = f_step))\n",
    "        hp_rec_fields.append(hp.Choice('rec_field_' + str(i), values = [3,5]))\n",
    "        hp_padding.append(hp.Choice('padding_' + str(i), values=['same','valid']))\n",
    "        hp_use_bias.append(hp.Boolean('use_bias_' + str(i)))\n",
    "        model.add(tf.keras.layers.Convolution2D(hp_filters[i], \n",
    "                                                hp_rec_fields[i], \n",
    "                                                padding=hp_padding[i], \n",
    "                                                use_bias=hp_use_bias[i],\n",
    "                                                input_shape = (28,28,1),\n",
    "                                                activation='tanh'))\n",
    "        # actually, the input_shape is only (28,28,1) for the bottom layer; I'm not sure why this syntax works, but\n",
    "        # it's possible (given how the documentation is worded) that this argument is just ignored in the later layers\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    #hp_units = hp.Int('proj_dim', min_value=32, max_value=512, step=32)\n",
    "    #model.add(tf.keras.layers.Dense(units=hp_units))                       # linear projection layer\n",
    "    model.add(tf.keras.layers.Dense(25, activation='softmax'))   # output layer\n",
    "    \n",
    "    # the optimiser is part of the hypermodel too\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26350b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to the documentation, a Hyperband search \"will run approximately max_epochs * (math.log(max_epochs, factor) ** 2) \n",
    "# cumulative epochs across all trials.\" \n",
    "conv_tuner_hypband = kt.Hyperband(conv_model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=20,\n",
    "                     factor=3)\n",
    "\n",
    "# since this dataset has 25 labels, uniform random guessing scores 0.04. this first callback is supposed to have the tuner \n",
    "# discard a model if it does not get at least 5% accuracy on the validation data (it happens from time to time that a model \n",
    "# gets stuck at the mean, effectively guessing each label with its frequency in the set, a bad local minimum). however, I'm \n",
    "# not altogether certain if/how it works. I do know that patience=0 does not do what I think it should.\n",
    "stop_failed = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', baseline=0.05, patience=1)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "callbacks = [stop_failed, stop_early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ebbd1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 06m 56s]\n",
      "val_accuracy: 0.6655047535896301\n",
      "\n",
      "Best val_accuracy So Far: 0.7143056392669678\n",
      "Total elapsed time: 02h 13m 21s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "conv_tuner_hypband.search(train_garg_square, train_garg_labels, \n",
    "                          validation_data=(test_garg_square, test_garg_labels), \n",
    "                          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0395ab22",
   "metadata": {},
   "source": [
    "Here are some results from an earlier iteration of this code which had better luck (and <i>max_layers</i> set to 3). The results were mixed, but they did agree on one thing: the learning rate they used was the least one of the options. So, in later experiments I let it go a bit lower. Needless to add, whatever conclusions I draw will be applicable at most to the current context: these models, this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e4943cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir\\intro_to_kt\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000001FB87C4EA30>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 48\n",
      "recField_0: 5\n",
      "padding_0: valid\n",
      "useBias_0: True\n",
      "conv_layers: 3\n",
      "units: 192\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 120\n",
      "recField_1: 3\n",
      "padding_1: valid\n",
      "useBias_1: True\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "conv_filters_2: 8\n",
      "recField_2: 3\n",
      "padding_2: same\n",
      "useBias_2: False\n",
      "tuner/trial_id: 0012\n",
      "Score: 0.745398759841919\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 48\n",
      "recField_0: 5\n",
      "padding_0: valid\n",
      "useBias_0: True\n",
      "conv_layers: 3\n",
      "units: 192\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 120\n",
      "recField_1: 3\n",
      "padding_1: valid\n",
      "useBias_1: True\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "conv_filters_2: 8\n",
      "recField_2: 3\n",
      "padding_2: same\n",
      "useBias_2: False\n",
      "tuner/trial_id: 0003\n",
      "Score: 0.7380089163780212\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 48\n",
      "recField_0: 5\n",
      "padding_0: valid\n",
      "useBias_0: True\n",
      "conv_layers: 3\n",
      "units: 192\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 120\n",
      "recField_1: 3\n",
      "padding_1: valid\n",
      "useBias_1: True\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "conv_filters_2: 8\n",
      "recField_2: 3\n",
      "padding_2: same\n",
      "useBias_2: False\n",
      "Score: 0.7179308533668518\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 120\n",
      "recField_0: 5\n",
      "padding_0: valid\n",
      "useBias_0: True\n",
      "conv_layers: 1\n",
      "units: 64\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 80\n",
      "recField_1: 3\n",
      "padding_1: valid\n",
      "useBias_1: False\n",
      "conv_filters_2: 72\n",
      "recField_2: 3\n",
      "padding_2: same\n",
      "useBias_2: True\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.6954824328422546\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 24\n",
      "recField_0: 3\n",
      "padding_0: same\n",
      "useBias_0: True\n",
      "conv_layers: 1\n",
      "units: 384\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 48\n",
      "recField_1: 3\n",
      "padding_1: same\n",
      "useBias_1: True\n",
      "conv_filters_2: 88\n",
      "recField_2: 3\n",
      "padding_2: same\n",
      "useBias_2: True\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0008\n",
      "Score: 0.6886503100395203\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 88\n",
      "recField_0: 5\n",
      "padding_0: same\n",
      "useBias_0: False\n",
      "conv_layers: 2\n",
      "units: 384\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 80\n",
      "recField_1: 5\n",
      "padding_1: valid\n",
      "useBias_1: False\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.6860011219978333\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 88\n",
      "recField_0: 3\n",
      "padding_0: valid\n",
      "useBias_0: True\n",
      "conv_layers: 2\n",
      "units: 64\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 48\n",
      "recField_1: 5\n",
      "padding_1: valid\n",
      "useBias_1: False\n",
      "conv_filters_2: 72\n",
      "recField_2: 5\n",
      "padding_2: valid\n",
      "useBias_2: True\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.6850250959396362\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 72\n",
      "recField_0: 5\n",
      "padding_0: same\n",
      "useBias_0: False\n",
      "conv_layers: 1\n",
      "units: 480\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 24\n",
      "recField_1: 3\n",
      "padding_1: same\n",
      "useBias_1: True\n",
      "conv_filters_2: 120\n",
      "recField_2: 3\n",
      "padding_2: valid\n",
      "useBias_2: True\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.6823759078979492\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 40\n",
      "recField_0: 5\n",
      "padding_0: same\n",
      "useBias_0: True\n",
      "conv_layers: 1\n",
      "units: 64\n",
      "learning_rate: 0.001\n",
      "conv_filters_1: 80\n",
      "recField_1: 5\n",
      "padding_1: valid\n",
      "useBias_1: False\n",
      "conv_filters_2: 16\n",
      "recField_2: 3\n",
      "padding_2: same\n",
      "useBias_2: True\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.6797267198562622\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 120\n",
      "recField_0: 5\n",
      "padding_0: valid\n",
      "useBias_0: True\n",
      "conv_layers: 1\n",
      "units: 64\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 80\n",
      "recField_1: 3\n",
      "padding_1: valid\n",
      "useBias_1: False\n",
      "conv_filters_2: 72\n",
      "recField_2: 3\n",
      "padding_2: same\n",
      "useBias_2: True\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0006\n",
      "Score: 0.6786112785339355\n"
     ]
    }
   ],
   "source": [
    "conv_tuner_hypband.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44120806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir\\intro_to_kt2\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000001FB87B5ABB0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 128\n",
      "recField_0: 3\n",
      "padding_0: same\n",
      "useBias_0: False\n",
      "conv_layers: 3\n",
      "units: 224\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 128\n",
      "recField_1: 5\n",
      "padding_1: valid\n",
      "useBias_1: True\n",
      "conv_filters_2: 8\n",
      "recField_2: 5\n",
      "padding_2: valid\n",
      "useBias_2: True\n",
      "Score: 0.7691020369529724\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 128\n",
      "recField_0: 3\n",
      "padding_0: same\n",
      "useBias_0: False\n",
      "conv_layers: 3\n",
      "units: 256\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 128\n",
      "recField_1: 5\n",
      "padding_1: valid\n",
      "useBias_1: True\n",
      "conv_filters_2: 8\n",
      "recField_2: 5\n",
      "padding_2: valid\n",
      "useBias_2: True\n",
      "Score: 0.7639431357383728\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 128\n",
      "recField_0: 3\n",
      "padding_0: same\n",
      "useBias_0: False\n",
      "conv_layers: 3\n",
      "units: 256\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 128\n",
      "recField_1: 5\n",
      "padding_1: valid\n",
      "useBias_1: True\n",
      "conv_filters_2: 8\n",
      "recField_2: 5\n",
      "padding_2: valid\n",
      "useBias_2: True\n",
      "Score: 0.7607361674308777\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 128\n",
      "recField_0: 3\n",
      "padding_0: same\n",
      "useBias_0: False\n",
      "conv_layers: 3\n",
      "units: 224\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 128\n",
      "recField_1: 5\n",
      "padding_1: valid\n",
      "useBias_1: True\n",
      "conv_filters_2: 8\n",
      "recField_2: 5\n",
      "padding_2: valid\n",
      "useBias_2: True\n",
      "Score: 0.7520914673805237\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 128\n",
      "recField_0: 3\n",
      "padding_0: same\n",
      "useBias_0: False\n",
      "conv_layers: 3\n",
      "units: 192\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 104\n",
      "recField_1: 5\n",
      "padding_1: valid\n",
      "useBias_1: True\n",
      "conv_filters_2: 8\n",
      "recField_2: 5\n",
      "padding_2: valid\n",
      "useBias_2: True\n",
      "Score: 0.751952052116394\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 128\n",
      "recField_0: 3\n",
      "padding_0: same\n",
      "useBias_0: False\n",
      "conv_layers: 3\n",
      "units: 256\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 128\n",
      "recField_1: 5\n",
      "padding_1: valid\n",
      "useBias_1: True\n",
      "conv_filters_2: 8\n",
      "recField_2: 5\n",
      "padding_2: valid\n",
      "useBias_2: True\n",
      "Score: 0.750976026058197\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 128\n",
      "recField_0: 3\n",
      "padding_0: same\n",
      "useBias_0: False\n",
      "conv_layers: 3\n",
      "units: 256\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 128\n",
      "recField_1: 5\n",
      "padding_1: valid\n",
      "useBias_1: True\n",
      "conv_filters_2: 8\n",
      "recField_2: 5\n",
      "padding_2: valid\n",
      "useBias_2: True\n",
      "Score: 0.7487451434135437\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 128\n",
      "recField_0: 3\n",
      "padding_0: same\n",
      "useBias_0: False\n",
      "conv_layers: 3\n",
      "units: 256\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 128\n",
      "recField_1: 5\n",
      "padding_1: valid\n",
      "useBias_1: True\n",
      "conv_filters_2: 8\n",
      "recField_2: 5\n",
      "padding_2: valid\n",
      "useBias_2: True\n",
      "Score: 0.746374785900116\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 128\n",
      "recField_0: 3\n",
      "padding_0: same\n",
      "useBias_0: False\n",
      "conv_layers: 3\n",
      "units: 256\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 128\n",
      "recField_1: 5\n",
      "padding_1: valid\n",
      "useBias_1: True\n",
      "conv_filters_2: 8\n",
      "recField_2: 5\n",
      "padding_2: valid\n",
      "useBias_2: True\n",
      "Score: 0.7459564805030823\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_filters_0: 128\n",
      "recField_0: 3\n",
      "padding_0: same\n",
      "useBias_0: False\n",
      "conv_layers: 3\n",
      "units: 256\n",
      "learning_rate: 0.0001\n",
      "conv_filters_1: 128\n",
      "recField_1: 5\n",
      "padding_1: valid\n",
      "useBias_1: True\n",
      "conv_filters_2: 8\n",
      "recField_2: 5\n",
      "padding_2: valid\n",
      "useBias_2: True\n",
      "Score: 0.7459564805030823\n"
     ]
    }
   ],
   "source": [
    "conv_tuner_bayes.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f440462e",
   "metadata": {},
   "source": [
    "Here's a later experiment looking at the effectiveness of a few regularisation methods, $L^2$ loss penalty and unit dropout. Actually the most significant change from above was the addition of a few pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d9f61cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model_builder_mk6(hp):\n",
    "    f_min, f_max, f_step=16, 256, 16\n",
    "    reg_coef = hp.Float('decay', min_value=0.05, max_value=0.15, step=0.01)\n",
    "    dropout_prob = hp.Float('dropout', min_value = 0.1, max_value = 0.5, step = 0.1)\n",
    "    regulator = tf.keras.regularizers.L2(reg_coef)\n",
    "    hp_filters, hp_rec_fields = [],[]\n",
    "    hp_units = hp.Int('units', min_value=64, max_value = 512, step=32)\n",
    "    for i in range(0,4):\n",
    "        hp_filters.append(hp.Int('conv_filters_' + str(i), min_value = f_min, max_value = f_max, step = f_step))\n",
    "        hp_rec_fields.append(hp.Choice('rec_field_' + str(i), values = [3,5]))\n",
    "    model = tf.keras.Sequential([tf.keras.layers.Convolution2D(hp_filters[0], hp_rec_fields[0], activation='relu', \n",
    "                                                               padding='same', use_bias = True,\n",
    "                                            input_shape = (128,128,3), kernel_regularizer=regulator),\n",
    "                                 tf.keras.layers.Dropout(dropout_prob),\n",
    "                                 tf.keras.layers.Convolution2D(hp_filters[1], hp_rec_fields[1], activation='relu', \n",
    "                                                               padding='same', use_bias = True,\n",
    "                                                              kernel_regularizer=regulator),\n",
    "                                 tf.keras.layers.MaxPool2D(strides=(2,2)), # default pool size (2,2); cuts down to 14x14x120\n",
    "                                 tf.keras.layers.Convolution2D(hp_filters[2], hp_rec_fields[2], activation='relu', \n",
    "                                                               padding='same', use_bias = True,\n",
    "                                                              kernel_regularizer=regulator),\n",
    "                                 tf.keras.layers.Dropout(dropout_prob),\n",
    "                                 tf.keras.layers.Convolution2D(hp_filters[3], hp_rec_fields[3], activation='relu', \n",
    "                                                               padding='same', use_bias = True,\n",
    "                                                              kernel_regularizer=regulator),\n",
    "                                 tf.keras.layers.MaxPool2D(strides=(2,2)), # cuts down to 7x7x96\n",
    "                                 tf.keras.layers.Flatten(),\n",
    "                                 tf.keras.layers.Dense(hp_units, activation='relu'),\n",
    "                                 tf.keras.layers.Dropout(dropout_prob),\n",
    "                                 tf.keras.layers.Dense(76, activation='softmax', kernel_regularizer=regulator)])\n",
    "                                 \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8241d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_tuner_hypband_6 = kt.Hyperband( conv_model_builder_mk6,\n",
    "                                     objective='val_accuracy',\n",
    "                                     max_epochs=20,\n",
    "                                     factor=3,\n",
    "                                     overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4a692a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 Complete [00h 37m 02s]\n",
      "val_accuracy: 0.5737590789794922\n",
      "\n",
      "Best val_accuracy So Far: 0.8753485679626465\n",
      "Total elapsed time: 11h 42m 52s\n",
      "\n",
      "Search: Running Trial #28\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.14              |0.06              |decay\n",
      "0.4               |0.2               |dropout\n",
      "320               |224               |units\n",
      "80                |64                |conv_filters_0\n",
      "3                 |5                 |rec_field_0\n",
      "80                |240               |conv_filters_1\n",
      "3                 |5                 |rec_field_1\n",
      "192               |48                |conv_filters_2\n",
      "5                 |3                 |rec_field_2\n",
      "144               |96                |conv_filters_3\n",
      "5                 |5                 |rec_field_3\n",
      "20                |20                |tuner/epochs\n",
      "0                 |7                 |tuner/initial_epoch\n",
      "0                 |2                 |tuner/bracket\n",
      "0                 |2                 |tuner/round\n",
      "\n",
      "Epoch 1/20\n",
      "531/858 [=================>............] - ETA: 1:45 - loss: 17.2451 - accuracy: 0.0459"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [162]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mconv_tuner_hypband_6\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_garg_square\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_garg_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_garg_square\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_garg_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mstop_early\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_failed\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:183\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 183\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\tuners\\hyperband.py:384\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    383\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/initial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(Hyperband, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:295\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    294\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m--> 295\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    297\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m    221\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 222\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    223\u001b[0m tuner_utils\u001b[38;5;241m.\u001b[39mvalidate_trial_results(\n\u001b[0;32m    224\u001b[0m     results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperModel.fit()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m )\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py:140\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conv_tuner_hypband_6.search(train_garg_square, train_garg_labels, validation_data=(test_garg_square, test_garg_labels), callbacks=[stop_early, stop_failed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e35604bf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir\\intro_to_kt7\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000001C7099858E0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "decay: 0.01\n",
      "dropout: 0.30000000000000004\n",
      "tuner/epochs: 50\n",
      "tuner/initial_epoch: 17\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0046\n",
      "Score: 0.9037925004959106\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "decay: 0.01\n",
      "dropout: 0.1\n",
      "tuner/epochs: 17\n",
      "tuner/initial_epoch: 6\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0035\n",
      "Score: 0.9022588133811951\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "decay: 0.01\n",
      "dropout: 0.2\n",
      "tuner/epochs: 6\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.8987730145454407\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "decay: 0.01\n",
      "dropout: 0.30000000000000004\n",
      "tuner/epochs: 6\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 3\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0024\n",
      "Score: 0.8943111896514893\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "decay: 0.01\n",
      "dropout: 0.30000000000000004\n",
      "tuner/epochs: 17\n",
      "tuner/initial_epoch: 6\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0036\n",
      "Score: 0.8933351635932922\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "decay: 0.02\n",
      "dropout: 0.1\n",
      "tuner/epochs: 6\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 3\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0015\n",
      "Score: 0.8931957483291626\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "decay: 0.03\n",
      "dropout: 0.30000000000000004\n",
      "tuner/epochs: 6\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.8905465602874756\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "decay: 0.02\n",
      "dropout: 0.4\n",
      "tuner/epochs: 6\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.889710009098053\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "decay: 0.01\n",
      "dropout: 0.1\n",
      "tuner/epochs: 6\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 3\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0006\n",
      "Score: 0.8867819309234619\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "decay: 0.02\n",
      "dropout: 0.2\n",
      "tuner/epochs: 6\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 3\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0030\n",
      "Score: 0.8863636255264282\n"
     ]
    }
   ],
   "source": [
    "conv_tuner_hypband_4.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0f2c76",
   "metadata": {},
   "source": [
    "I was surprised at how poorly the early models generalised to the test set, compared to the training set, where they frequently got accuracy between 0.98 and 1 after just a few epochs. Eventually I tried making a test/train split just within the \"sign_mnist_train\" dataset; on this split the model's accuracy was the same on both parts. Then I tried mixing the two \"sign_mnist\" datasets and making a different test/train split from it, with the same result. Evidently the dataset author did do something different in processing their test image set, which they did not mention. I have mixed feelings about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7fad9cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "486bc955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34627, 785)\n"
     ]
    }
   ],
   "source": [
    "mixed_temp = pd.concat([train_garg, test_garg], ignore_index=True)\n",
    "print(mixed_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "656ad50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp, test_temp = train_test_split(mixed_temp)\n",
    "\n",
    "train_temp_square = train_temp.drop('label',axis=1).to_numpy().reshape((train_temp.shape[0], 28, 28))\n",
    "test_temp_square = test_temp.drop('label',axis=1).to_numpy().reshape((test_temp.shape[0],28,28))\n",
    "\n",
    "train_temp_square = np.float32(train_temp_square) / 255\n",
    "test_temp_square = np.float32(test_temp_square) / 255\n",
    "\n",
    "train_temp_labels = train_temp['label'].to_numpy()\n",
    "test_temp_labels = test_temp['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e4c03421",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = conv_model_builder_mk4(conv_tuner_hypband_4.get_best_hyperparameters()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fb4d1a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "812/812 [==============================] - 158s 193ms/step - loss: 3.8487 - accuracy: 0.5992\n",
      "271/271 - 12s - loss: 2.1316 - accuracy: 0.8798 - 12s/epoch - 45ms/step\n",
      "812/812 [==============================] - 159s 195ms/step - loss: 1.5749 - accuracy: 0.9254\n",
      "271/271 - 12s - loss: 1.0721 - accuracy: 0.9876 - 12s/epoch - 46ms/step\n",
      "812/812 [==============================] - 161s 199ms/step - loss: 0.8711 - accuracy: 0.9821\n",
      "271/271 - 13s - loss: 0.6501 - accuracy: 0.9998 - 13s/epoch - 49ms/step\n",
      "812/812 [==============================] - 162s 200ms/step - loss: 0.5668 - accuracy: 0.9943\n",
      "271/271 - 12s - loss: 0.4610 - accuracy: 0.9991 - 12s/epoch - 46ms/step\n",
      "812/812 [==============================] - 162s 200ms/step - loss: 0.4260 - accuracy: 0.9964\n",
      "271/271 - 12s - loss: 0.3665 - accuracy: 0.9999 - 12s/epoch - 45ms/step\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for i in range(0,epochs):\n",
    "    model.fit(train_temp_square, train_temp_labels, epochs = 1)\n",
    "    model.evaluate(test_temp_square, test_temp_labels, verbose=2)\n",
    "    \n",
    "# val_acc reported is larger than immediately preceding acc on the training set because the latter is some kind of \n",
    "# average over the training epoch, while the former is computed only from the model at the epoch's end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "328df7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25970, 28, 28) (8657, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_temp_square.shape, test_temp_square.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b50ec437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{a for a in train_temp.index if a in test_temp.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6098ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this baby model doesn't reach the same accuracy, but it likewise has zero generalisation error on this data split\n",
    "tiny_model = tf.keras.Sequential([tf.keras.layers.Flatten(input_shape = (28,28,1)),  \n",
    "                            tf.keras.layers.Dense(128, activation='relu'), \n",
    "                            tf.keras.layers.Dense(25),\n",
    "                            tf.keras.layers.Softmax()])\n",
    "\n",
    "tiny_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b6b9b767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "812/812 [==============================] - 1s 1ms/step - loss: 2.8720 - accuracy: 0.2052\n",
      "271/271 - 0s - loss: 2.5121 - accuracy: 0.3504 - 361ms/epoch - 1ms/step\n",
      "812/812 [==============================] - 1s 1ms/step - loss: 2.2293 - accuracy: 0.4395\n",
      "271/271 - 0s - loss: 2.0093 - accuracy: 0.4895 - 280ms/epoch - 1ms/step\n",
      "812/812 [==============================] - 1s 1ms/step - loss: 1.8430 - accuracy: 0.5369\n",
      "271/271 - 0s - loss: 1.7188 - accuracy: 0.5623 - 260ms/epoch - 961us/step\n",
      "812/812 [==============================] - 1s 1ms/step - loss: 1.6004 - accuracy: 0.5891\n",
      "271/271 - 0s - loss: 1.5184 - accuracy: 0.5963 - 250ms/epoch - 922us/step\n",
      "812/812 [==============================] - 1s 1ms/step - loss: 1.4304 - accuracy: 0.6317\n",
      "271/271 - 0s - loss: 1.3636 - accuracy: 0.6615 - 251ms/epoch - 926us/step\n",
      "812/812 [==============================] - 1s 1ms/step - loss: 1.3042 - accuracy: 0.6637\n",
      "271/271 - 0s - loss: 1.2660 - accuracy: 0.6649 - 251ms/epoch - 928us/step\n",
      "812/812 [==============================] - 1s 1ms/step - loss: 1.2024 - accuracy: 0.6900\n",
      "271/271 - 0s - loss: 1.1633 - accuracy: 0.6905 - 247ms/epoch - 913us/step\n",
      "812/812 [==============================] - 1s 1ms/step - loss: 1.1181 - accuracy: 0.7118\n",
      "271/271 - 0s - loss: 1.0841 - accuracy: 0.7120 - 240ms/epoch - 885us/step\n",
      "812/812 [==============================] - 1s 1ms/step - loss: 1.0430 - accuracy: 0.7343\n",
      "271/271 - 0s - loss: 1.0326 - accuracy: 0.7223 - 243ms/epoch - 898us/step\n",
      "812/812 [==============================] - 1s 1ms/step - loss: 0.9792 - accuracy: 0.7511\n",
      "271/271 - 0s - loss: 0.9604 - accuracy: 0.7553 - 245ms/epoch - 905us/step\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for i in range(0,epochs):\n",
    "    tiny_model.fit(train_temp_square, train_temp_labels, epochs = 1)\n",
    "    tiny_model.evaluate(test_temp_square, test_temp_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a57a5e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 1, 120)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weights = model.get_weights()[0]\n",
    "test_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "08e1e230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c3431db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filters = np.split(test_weights, 120, axis=3)\n",
    "test_filters = np.squeeze(test_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ad00ccf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 59 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1,60):\n",
    "    plt.subplot(10,6,i)\n",
    "    plt.imshow(test_filters[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4d7dde83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 59 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1,60):\n",
    "    plt.subplot(10,6,i)\n",
    "    plt.imshow(test_filters[i+59])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba0d54a",
   "metadata": {},
   "source": [
    "<h3>Customised blocks</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1eaf8676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_train_images = np.expand_dims(fashion_train_images, 3)\n",
    "fashion_test_images = np.expand_dims(fashion_test_images,3)\n",
    "fashion_train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be433343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testBlock(tf.keras.Model):\n",
    "    def __init__(self, labels, filters, rec_field):\n",
    "        super(testBlock, self).__init__()\n",
    "        \n",
    "        self.conv_1 = tf.keras.layers.Convolution2D(filters, rec_field, padding='same', use_bias=True, activation='tanh')\n",
    "        self.conv_2 = tf.keras.layers.Convolution2D(filters, rec_field, padding='same', use_bias=True, activation='tanh')\n",
    "        self.conv_3 = tf.keras.layers.Convolution2D(filters, rec_field, padding='same', use_bias=True, activation='tanh')\n",
    "        self.collate = tf.keras.layers.Dense(labels, activation='softmax')\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        out_base = self.conv_1(input_tensor)\n",
    "        out = self.conv_2(out_base)\n",
    "        out = tf.raw_ops.Concat(concat_dim=3, values=[out, out_base]) # skip connection\n",
    "        out = self.conv_3(out)\n",
    "        out = tf.keras.layers.MaxPool2D(strides=(2,2))(out)\n",
    "        out = tf.keras.layers.Flatten()(out)\n",
    "        out = self.collate(out)\n",
    "        return out       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93615ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel = testBlock(10, 32, 3)\n",
    "\n",
    "testModel.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe172bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 120s 64ms/step - loss: 0.3320 - accuracy: 0.8839\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 153s 82ms/step - loss: 0.2691 - accuracy: 0.9056\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 219s 117ms/step - loss: 0.2384 - accuracy: 0.9151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f44f9adf0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testModel.fit(fashion_train_images, fashion_train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79e751e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 11s - loss: 0.3085 - accuracy: 0.8887 - 11s/epoch - 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3084518611431122, 0.888700008392334]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testModel.evaluate(fashion_test_images,  fashion_test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "754f8d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_block_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          multiple                  320       \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          multiple                  9248      \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          multiple                  18464     \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  62730     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 90,762\n",
      "Trainable params: 90,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "testModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0e422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
