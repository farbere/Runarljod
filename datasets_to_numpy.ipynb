{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83b5a410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b64df6",
   "metadata": {},
   "source": [
    "<h3>Datasets to numpy arrays</h3>\n",
    "\n",
    "This collection of scripts takes some of the various datasets we've seen and converts them to a pair of numpy arrays, one for images and one for labels. The processing is all idiosyncratic because of the varying presentations and compositions of the datasets. \"labels\" entries are python dicts containing all the metadata I think we might want to know when manipulating these sets in the future. The most important keys are 'dataset', 'subgroup', and 'sign'. 'sign' is the classifying label in the ML sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bcce908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dict of all the keys and values that appear (except 'subgroup') in datasets I've tagged\n",
    "# this isn't used for anything yet (maybe never will)\n",
    "keywords={'dataset':['cap','dis','grass','mav1','mav2','urgarg'],'subgroup':['none'], 'colour':['greyscale','rbg','bgr'], \n",
    "          'crop':['close','none'], 'size':['small','large','128'], 'shape':['square', 'rectangle'],\n",
    "         'fill':['gauss','uniform','int','zeros']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9a1729",
   "metadata": {},
   "source": [
    "<b>Dataset: CAP</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e8603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a530abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Path(\"bak/Dataset (CAP)/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5663afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in d.iterdir():\n",
    "    for file in letter.iterdir():\n",
    "        images.append(cv.imread(str(file)))\n",
    "        if not file.name[4].isdigit():\n",
    "            subgrp = \"model2\" \n",
    "        elif int(file.name[4]) > 5:\n",
    "            subgrp = \"model2\"\n",
    "        else:\n",
    "            subgrp = \"model1\"     \n",
    "        labels.append({'dataset': \"cap\", 'subgroup':subgrp, 'sign': letter.stem, \n",
    "                       'colour':'greyscale', 'crop':'close', 'size':'large', 'shape':'square'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20129832",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Path(\"bak/Dataset (CAP)/val\")\n",
    "# and re-run the last cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "560cb904",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Path(\"bak/Dataset (CAP)/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b698c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in d.iterdir():\n",
    "    flist = [file for file in letter.iterdir()]\n",
    "    dirsize = len(flist)\n",
    "    for file in letter.iterdir():\n",
    "        images.append(cv.imread(str(file)))\n",
    "        if len(file.name) > 10:\n",
    "            if not file.name[10].isdigit():\n",
    "                subgrp = \"model1\"\n",
    "            elif (dirsize - int(file.name[9:11])) < 30:\n",
    "                subgrp = \"model2\"\n",
    "            else:\n",
    "                subgrp = \"model1\"\n",
    "        else:\n",
    "            if not file.name[4].isdigit():\n",
    "                subgrp = \"model1\"\n",
    "            elif (dirsize - int(file.name[3:5])) < 30:\n",
    "                subgrp = \"model2\"\n",
    "            else:\n",
    "                subgrp = \"model1\"\n",
    "        labels.append({'dataset': \"cap\", 'subgroup':subgrp, 'sign': letter.stem, \n",
    "                       'colour':'greyscale', 'crop':'close', 'size':'large', 'shape':'square'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "396ae9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2282 2282\n"
     ]
    }
   ],
   "source": [
    "print(len(images), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95bbe4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"datasets/img_cap.npy\", images)\n",
    "np.save(\"datasets/lbl_cap.npy\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c829dd68",
   "metadata": {},
   "source": [
    "<b>Dataset: dis</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c1c5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89c88cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Path(\"bak/Dataset (dis)/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b0542bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sign in d.iterdir():\n",
    "    for file in sign.iterdir():\n",
    "        images.append(cv.imread(str(file)))\n",
    "        labels.append({'dataset':'dis', 'subgroup':file.name[0:5], 'sign':sign.stem, \n",
    "                       'colour': 'bgr', 'crop': 'close', 'size':'large', 'shape':'square'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2628deec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2515 2515\n"
     ]
    }
   ],
   "source": [
    "print(len(images), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6d7bf22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"datasets/img_dis.npy\", images)\n",
    "np.save(\"datasets/lbl_dis.npy\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf37cc4",
   "metadata": {},
   "source": [
    "<b>Dataset: grass</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e610ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cda7c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=Path(\"bak/dataset (grass)/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aff0fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude=['K', 'G', 'M', 'N', 'P', 'T', 'nothing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8385035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in d.iterdir():\n",
    "    if folder.is_file():\n",
    "        continue\n",
    "    if folder.name in exclude:\n",
    "        continue\n",
    "    for file in folder.iterdir():\n",
    "        if not file.name[-6].isdigit():\n",
    "            continue\n",
    "        if file.name[-5] == '0' and int(file.name[-6]) % 2 == 0:\n",
    "            images.append(cv.imread(str(file)))\n",
    "            #1000, 2000, 2500\n",
    "            if folder.stem=='del':\n",
    "                if len(file.name) < 11:\n",
    "                    source = 'video1'\n",
    "                else:\n",
    "                    id = int(file.name[3:7])\n",
    "                    if id == 1000:\n",
    "                        source = 'video1'\n",
    "                    if 1000 < id <= 2000:\n",
    "                        source = 'video2'\n",
    "                    if 2000< id <=2500:\n",
    "                        source = 'video3'\n",
    "                    if 2500<id <= 3000:\n",
    "                        source = 'video4'\n",
    "                        \n",
    "            elif folder.stem=='space':\n",
    "                    if len(file.name) < 13:\n",
    "                        source = 'video1'\n",
    "                    else:\n",
    "                        id = int(file.name[5:9])\n",
    "                        if id == 1000:\n",
    "                            source = 'video1'\n",
    "                        if 1000 < id <= 2000:\n",
    "                            source = 'video2'\n",
    "                        if 2000< id <=2500:\n",
    "                            source = 'video3'\n",
    "                        if 2500<id <= 3000:\n",
    "                            source = 'video4'\n",
    "            elif len(file.name) < 9:\n",
    "                source = 'video1'\n",
    "            else:\n",
    "                id = int(file.name[1:5])\n",
    "                if id == 1000:\n",
    "                    source = 'video1'\n",
    "                if 1000 < id <= 2000:\n",
    "                    source = 'video2'\n",
    "                if 2000< id <=2500:\n",
    "                    source = 'video3'\n",
    "                if 2500<id <= 3000:\n",
    "                    source = 'video4'\n",
    "            labels.append({'dataset':'grass', 'subgroup':source, 'sign':folder.stem, \n",
    "                           'colour':'bgr', 'crop':'close','size': 'large', 'shape':'square'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6372c833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300 3300\n"
     ]
    }
   ],
   "source": [
    "print(len(images), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b04eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"datasets/bak/img_grass.npy\", images)\n",
    "np.save(\"datasets/bak/lbl_grass.npy\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7c84ed",
   "metadata": {},
   "source": [
    "<b>Dataset: mav1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3b38d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "images =[]\n",
    "labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "de9ce96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Path(\"bak/dataset (mav1)/images (colour)/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "197e192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for numeral in d.iterdir():\n",
    "    for file in numeral.iterdir():\n",
    "        images.append(cv.imread(str(file)))\n",
    "        labels.append({'dataset':'mav1', 'subgroup':'none', 'sign':numeral.stem, \n",
    "                       'colour':'bgr', 'crop':'close', 'size':'small', 'shape':'square'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "db101296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2059 2059\n"
     ]
    }
   ],
   "source": [
    "print(len(images),len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "358efaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"datasets/img_mav1.npy\", images)\n",
    "np.save(\"datasets/lbl_mav1.npy\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9c90e",
   "metadata": {},
   "source": [
    "<b>Dataset: mav2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d6d97587",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(\"bak/dataset (mav2)/x.npy\")\n",
    "labels = np.load(\"bak/dataset (mav2)/y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "906564fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.uint8(images*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cbb55e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_temp = labels.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a9e3ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for lbl in labels_temp:\n",
    "    labels.append({'dataset':'mav2', 'subgroup':'none', 'sign':lbl,\n",
    "                    'colour':'rgb', 'crop':'close', 'size':'128', 'shape':'square'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "83633c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"datasets/img_mav2.npy\", images)\n",
    "np.save(\"datasets/lbl_mav2.npy\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4679c3",
   "metadata": {},
   "source": [
    "<b>Dataset: ur-garg</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d462f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Path(\"bak/dataset (ur-garg)/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "201f8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "078a96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in d.iterdir():\n",
    "    for file in user.iterdir():\n",
    "        if file.suffix != \".jpg\":\n",
    "            continue\n",
    "        images.append(cv.imread(str(file)))\n",
    "        labels.append({'dataset':'urgarg', 'subgroup':user.stem, 'sign':file.name[0], \n",
    "                       'colour':'bgr', 'crop':'none', 'size':'large', 'shape':'rectangle'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5915aaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1680 1680\n"
     ]
    }
   ],
   "source": [
    "print(len(images),len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6f12e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"datasets/img_urgarg.npy\", images)\n",
    "np.save(\"datasets/lbl_urgarg.npy\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec293b",
   "metadata": {},
   "source": [
    "<b>Dataset: Lee</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d84b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d8604f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=Path(\"inbox/Lee/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "612fa72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for frame in d.iterdir():\n",
    "    if j % 3 == 0:\n",
    "        images.append(cv.imread(str(frame)))\n",
    "        labels.append({'dataset':'lee', 'subgroup':'none', 'sign':frame.name[0],\n",
    "                    'colour':'bgr', 'crop':'close', 'size':'large', 'shape':'square'})\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1322bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=Path('inbox/Lee/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfbeb24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=Path('inbox/Lee/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f020c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in d.iterdir():\n",
    "    images.append(cv.imread(str(frame)))\n",
    "    labels.append({'dataset':'lee', 'subgroup':'none', 'sign':frame.name[0],\n",
    "                    'colour':'bgr', 'crop':'close', 'size':'large', 'shape':'square'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8ec8e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"datasets/bak/img_lee.npy\", images)\n",
    "np.save(\"datasets/bak/lbl_lee.npy\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da649715",
   "metadata": {},
   "source": [
    "<b>Dataset: Arikari</b>\n",
    "\n",
    "https://www.kaggle.com/datasets/prathumarikeri/indian-sign-language-isl\n",
    "\n",
    "Although I like the idea of expanding our label space (there's an idea that training models to do additional, related tasks can help them with their original goals), as long as the frames can't be split among train/val/hold it sounds like more trouble than it's worth. So I removed these from my working dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00523252",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace = {'3':'w', '6':'i', '8':'3'}\n",
    "twohand = ['a', 'b', 'd','e','f','g','h','j','k','m','n','p','q','r','s','t','w','x','y','z']\n",
    "exclude = ['c','i','o','v']\n",
    "keep = ['l']\n",
    "Indian = ['7', '9','u']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb24358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"inbox/Indian (Arikeri)/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c42381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "193ca214",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in replace.keys():\n",
    "    for frame in Path(d+key).iterdir():\n",
    "        if len(frame.name) < 6:\n",
    "            continue\n",
    "        if frame.name[-5] == '0' and (frame.name[-6] == '0' or frame.name[-6] == '5'):\n",
    "            images.append(cv.imread(str(frame)))\n",
    "            labels.append({'dataset':'arikeri', 'subgroup':'single_model', 'sign':replace[key],\n",
    "                          'colour':'bgr', 'crop':'close', 'size':'128', 'shape':'square'})\n",
    "for letter in keep:\n",
    "    for frame in Path(d+letter).iterdir():\n",
    "        if len(frame.name) < 6:\n",
    "            continue\n",
    "        if frame.name[-5] == '0' and (frame.name[-6] == '0' or frame.name[-6] == '5'):\n",
    "            images.append(cv.imread(str(frame)))\n",
    "            labels.append({'dataset':'arikeri', 'subgroup':'single_model', 'sign':letter,\n",
    "                          'colour':'bgr', 'crop':'close', 'size':'128', 'shape':'square'})\n",
    "for letter in Indian:\n",
    "    for frame in Path(d+letter).iterdir():\n",
    "        if len(frame.name) < 6:\n",
    "            continue\n",
    "        if frame.name[-5] == '0' and (frame.name[-6] == '0' or frame.name[-6] == '5'):\n",
    "            images.append(cv.imread(str(frame)))\n",
    "            labels.append({'dataset':'arikeri', 'subgroup':'single_model', 'sign':'Ind_'+letter,\n",
    "                          'colour':'bgr', 'crop':'close', 'size':'128', 'shape':'square'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "60a83cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"datasets/bak/img_ari.npy\", images)\n",
    "np.save(\"datasets/bak/lbl_ari.npy\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e18e5c",
   "metadata": {},
   "source": [
    "<b>Dataset: Bredun</b>\n",
    "\n",
    "https://www.kaggle.com/datasets/ruslanbredun/sign-language-eng-alphabet\n",
    "\n",
    "Since this is another single-model dataset, everything picked out from it will be going into the train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54172b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Path(\"bak/dataset (bredun)/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1652c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "116bdf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in d.iterdir():\n",
    "    for frame in letter.iterdir():\n",
    "        if len(frame.name) < 6:\n",
    "            continue\n",
    "        if frame.name[-5] == '0' and (frame.name[-6] in ['0', '3', '6']):\n",
    "            images.append(cv.imread(str(frame)))\n",
    "            labels.append({'dataset':'bredun', 'subgroup':'single_model', 'sign':letter.name,\n",
    "                          'colour':'bgr', 'crop':'close', 'size':'large', 'shape':'square'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8afd6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"datasets/bak/img_bredun.npy\", images)\n",
    "np.save(\"datasets/bak/lbl_bredun.npy\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908acd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
