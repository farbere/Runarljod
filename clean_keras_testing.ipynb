{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation ##\n",
    "\n",
    "This is Ethan's attempt to extract the 'fourth pass' from the keras_testing notebook.\n",
    "\n",
    "That pass is currently (as of Dec 5 before our meeting) the model whose weights we are planning to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 13:33:56.063524: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic datasets: train and val at 64x64\n",
    "train_img_small = np.load('datasets/train_img_64.npy')\n",
    "train_img_small = np.float32(train_img_small) / 255\n",
    "train_geom = np.concatenate([np.load(\"datasets/train_geom_img.npy\"), np.load(\"datasets/train_geom_wrl.npy\")], axis=1)\n",
    "train_geom = train_geom.reshape((-1, 21*6))\n",
    "train_lbl = np.load('datasets/train_lbl.npy')\n",
    "print(train_img_small.shape, train_geom.shape, train_lbl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_small = np.load('datasets/val_img_64.npy')\n",
    "val_img_small = np.float32(val_img_small) / 255\n",
    "val_geom = np.concatenate([np.load(\"datasets/val_geom_img.npy\"), np.load(\"datasets/val_geom_wrl.npy\")], axis=1)\n",
    "val_geom = val_geom.reshape((-1,21*6))\n",
    "val_lbl = np.load('datasets/val_lbl.npy')\n",
    "print(val_img_small.shape, val_geom.shape, val_lbl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic data pre-generated by albumentations\n",
    "train_img_synth = np.concatenate([np.load('datasets/train_img_64_synth.npy'), \n",
    "                                  np.load('datasets/train_img_64.npy')], axis=0)\n",
    "train_lbl_synth = np.concatenate([np.load('datasets/train_lbl_64_synth.npy'), \n",
    "                                  np.load('datasets/train_lbl.npy')], axis=0)\n",
    "train_geom_synth = np.concatenate([np.concatenate([np.load('datasets/train_geom_img_64_synth.npy'), \n",
    "                                                   np.load('datasets/train_geom_img.npy')], axis=1),\n",
    "                                   np.concatenate([np.load('datasets/train_geom_wrl_64_synth.npy'),\n",
    "                                                   np.load('datasets/train_geom_wrl.npy')], axis=1)],\n",
    "                                   axis=0)\n",
    "train_img_synth = np.float32(train_img_synth) / 255\n",
    "train_geom_synth = train_geom_synth.reshape((-1, 21*6))\n",
    "print(train_img_synth.shape, train_geom_synth.shape, train_lbl_synth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(seq):\n",
    "    if tf.random.categorical(tf.math.log([[0.5, 0.5]]), 1).numpy()[0][0]:\n",
    "        return tf.raw_ops.Reverse(tensor=seq, dims=[False,False,False,True,False])\n",
    "    return seq\n",
    "\n",
    "def random_augment(seq):\n",
    "    seq = random_flip(seq)\n",
    "    seq = tf.image.random_brightness(seq, 0.15)\n",
    "    seq = tf.image.random_saturation(seq, 0.85, 1.15)\n",
    "    seq = tf.image.random_contrast(seq, 0.85, 1.15)\n",
    "    #seq = tf.image.random_hue(seq, 0.01)\n",
    "    return tf.raw_ops.ClipByValue(t=seq, clip_value_min=0, clip_value_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesiser_train = tf.keras.Sequential([tf.keras.layers.RandomBrightness(0.2, value_range=(0,1)),\n",
    "                                    tf.keras.layers.RandomFlip(mode = 'horizontal'),\n",
    "                                    tf.keras.layers.RandomRotation(0.05, fill_mode='constant'),\n",
    "                                    tf.keras.layers.RandomZoom(height_factor=0.2, fill_mode='constant')])\n",
    "batch_size = train_img_synth.shape[0]\n",
    "train_img_tf = tf.data.Dataset.from_tensor_slices(train_img_synth)\n",
    "train_geom_tf = tf.data.Dataset.from_tensor_slices(train_geom_synth).batch(batch_size).get_single_element()\n",
    "\n",
    "\n",
    "# this makes a dataset object with an attached function, rather than just applying a function once to its tensors\n",
    "train_synth = train_img_tf.map(lambda x: synthesiser_train(x),\n",
    "                                 num_parallel_calls=batch_size).batch(batch_size)\n",
    "train_proc = train_synth.get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testAttentionModel(tf.keras.Model):\n",
    "    def __init__(self, conv_filters, reg_coef=0, labels=50, use_geom_backup=True):\n",
    "        super(testAttentionModel, self).__init__()\n",
    "        filters_1, filters_2, filters_3 = conv_filters\n",
    "        conv_out_size = filters_3\n",
    "        self.reg = tf.keras.regularizers.L2(reg_coef)\n",
    "        self.spatial_dropout_prob = 0.02\n",
    "        self.dropout_prob = 0.1\n",
    "        self.use_geom_backup = use_geom_backup\n",
    "        \n",
    "        \n",
    "        # 64x64xch\n",
    "        self.conv_1a = tf.keras.layers.Convolution2D(filters_1, 5, padding='same', use_bias=True, \n",
    "                                                     activation='relu',\n",
    "                                                     kernel_regularizer=self.reg)\n",
    "        self.conv_1b = tf.keras.layers.Convolution2D(filters_1, 3, padding='same', use_bias=True, \n",
    "                                                     activation='relu',\n",
    "                                                     kernel_regularizer=self.reg)\n",
    "        # 32x32xch\n",
    "        self.conv_2a = tf.keras.layers.Convolution2D(filters_2, 3, padding='same', use_bias=True, \n",
    "                                                     activation='relu',\n",
    "                                                     kernel_regularizer=self.reg)\n",
    "        self.conv_2b = tf.keras.layers.Convolution2D(filters_2, 3, padding='same', use_bias=True,\n",
    "                                                     activation='relu',\n",
    "                                                     kernel_regularizer=self.reg)\n",
    "        # 16x16xch\n",
    "        self.conv_3a = tf.keras.layers.Convolution2D(filters_3, 3, padding='same', use_bias=True, \n",
    "                                                     activation='relu',\n",
    "                                                    kernel_regularizer=self.reg)\n",
    "        self.conv_3b = tf.keras.layers.Convolution2D(filters_3, 3, padding='same', use_bias=True, \n",
    "                                                     activation='relu',\n",
    "                                                     kernel_regularizer=self.reg)\n",
    "        # 8x8xch\n",
    "        #self.conv_4a = tf.keras.layers.Convolution2D(filters_4, 3, padding='same', use_bias=True, activation='relu')\n",
    "                                                    # activation='tanh', kernel_regularizer=regulator)\n",
    "        #self.conv_4b = tf.keras.layers.Convolution2D(filters_4, 3, padding='same', use_bias=True, activation='relu')\n",
    "                                                     #activation='tanh', kernel_regularizer=regulator)\n",
    "        # out: 4x4xch\n",
    "        \n",
    "        self.geom1 = tf.keras.layers.Dense(64, use_bias=True, activation='relu', kernel_regularizer=self.reg)\n",
    "        self.geom_backup = tf.keras.layers.Dense(64, use_bias=True, activation='relu', kernel_regularizer=self.reg)\n",
    "        self.geom2 = tf.keras.layers.Dense(64, use_bias=True, activation='relu', kernel_regularizer=self.reg)\n",
    "        self.attention = tf.keras.layers.Dense(conv_out_size, use_bias=True, \n",
    "                                               activation='softmax', kernel_regularizer=self.reg)\n",
    "\n",
    "        self.classifier = tf.keras.layers.Dense(labels, activation='softmax')\n",
    "    \n",
    "    def call(self, input_list, training=True):\n",
    "        c_out = tf.keras.layers.GaussianNoise(0.03)(input_list[0], #start 64x64x3\n",
    "                                                    training=training)\n",
    "        c_out = tf.keras.layers.SpatialDropout2D(self.spatial_dropout_prob)(self.conv_1a(c_out),\n",
    "                                                                            training=training)\n",
    "        c_out = tf.keras.layers.MaxPool2D(strides=(2,2))(self.conv_1b(c_out)) # to 32x32xch\n",
    "        c_out = tf.keras.layers.SpatialDropout2D(self.spatial_dropout_prob)(self.conv_2a(c_out),\n",
    "                                                                            training=training)\n",
    "        c_out = tf.keras.layers.MaxPool2D(strides=(2,2))(self.conv_2b(c_out))\n",
    "        c_out = tf.keras.layers.SpatialDropout2D(self.spatial_dropout_prob) (self.conv_3a(c_out),\n",
    "                                                                            training=training)\n",
    "        c_out = tf.keras.layers.MaxPool2D(strides=(2,2))(self.conv_3b(c_out)) # to 16x16xch\n",
    "        #c_out = self.conv_4a(c_out)\n",
    "        #c_out = tf.keras.layers.MaxPool2D(strides=(2,2))(self.conv_4b(c_out))\n",
    "       \n",
    "        if tf.math.reduce_max(input_list[1]) == 0 and self.use_geom_backup:\n",
    "            g_out = self.geom_backup(tf.keras.layers.Flatten()(tf.keras.layers.AveragePooling2D(pool_size=(4, 4),\n",
    "                                                                                                strides=(4,4),\n",
    "                                                                                                padding='valid')(input_list[0])))\n",
    "        else:\n",
    "            g_out = self.geom1(input_list[1]) # if use_geom_backup is off this will output max(0, bias)\n",
    "        g_out = tf.keras.layers.Dropout(self.dropout_prob)(g_out, training=training)\n",
    "        g_out = tf.keras.layers.Dropout(self.dropout_prob)(self.geom2(g_out),training=training)\n",
    "        g_out = tf.keras.layers.Dropout(self.dropout_prob)(self.attention(g_out),training=training)\n",
    "        g_out = tf.expand_dims(tf.expand_dims(g_out, axis=-2), axis=-2)\n",
    "       \n",
    "        return self.classifier(tf.keras.layers.Flatten()(tf.math.multiply(c_out, g_out)))\n",
    "    \n",
    "    #def build_graph(self):\n",
    "    #    in1 = tf.keras.layers.Input(shape=(64,64,3))\n",
    "    #    in2 = tf.keras.layers.Input(shape=(63))\n",
    "    #    return tf.keras.Model(inputs=[in1,in2], \n",
    "    #                          outputs=self.call([in1,in2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAttender = testAttentionModel((64,128,256), reg_coef=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.0001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                    learning_rate,\n",
    "                    decay_steps=5000,\n",
    "                    decay_rate=0.9,\n",
    "                    staircase=True)\n",
    "\n",
    "testAttender.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balin's notes ##\n",
    "\n",
    "Results: 0.790 (0.964) with 3 blocks 64/128/256. Reg at 0.001 didn't help, 0.77 (0.966). (At this point cut half of the dataset grass.) Added spatial/regular dropout at 0.04/0.2, reg=0.001. Slower, val stalled around .745 (tr continued up to .93). adding in synth data, tr_acc (on the same model) went down to .745 too. but though it recovered val did not.\n",
    "\n",
    "With everything on (noise, dropouts, reg, pre-built synth, train-time synth), up to .82 (.96)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAttender.fit([train_proc, train_geom_tf], train_lbl_synth,\n",
    "                 validation_data=([val_img_small, val_geom], val_lbl),\n",
    "                 epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAttender.save_weights(\"testAttender.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why two copies of the same object? because tensorflow handles batch size in a way I don't understand, and\n",
    "# using the same one in two places raises errors\n",
    "synthesiser_val = tf.keras.Sequential([tf.keras.layers.RandomBrightness(0.2, value_range=(0,1)),\n",
    "                                    tf.keras.layers.RandomFlip(mode = 'horizontal'),\n",
    "                                    tf.keras.layers.RandomRotation(0.05, fill_mode='constant'),\n",
    "                                    tf.keras.layers.RandomZoom(height_factor=0.2, fill_mode='constant')])\n",
    "batch_val = val_img_small.shape[0]\n",
    "val_img_tf = tf.data.Dataset.from_tensor_slices(val_img_small)\n",
    "val_geom_tf = tf.data.Dataset.from_tensor_slices(val_geom_full).batch(batch_val).get_single_element()\n",
    "val_lbl_tf = tf.data.Dataset.from_tensor_slices(val_lbl_small).batch(batch_val).get_single_element()\n",
    "\n",
    "val_synth_ds = val_img_tf.map(lambda x: synthesiser_val(x),\n",
    "                             num_parallel_calls=batch_val).batch(batch_val)\n",
    "val_proc = val_synth_ds.get_single_element()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c452e763028db92424a1175d699ff5e0725780886d15c6f44eb3a879cb3830b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
