{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccbd0c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8121c3",
   "metadata": {},
   "source": [
    "<b>First pass</b>: ordinary, small convolutional networks given image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6320685",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_small = np.load('datasets/train_img_64.npy')\n",
    "train_lbl_small = np.load('datasets/train_lbl_64.npy')\n",
    "val_img_small = np.load('datasets/val_img_64.npy')\n",
    "val_lbl_small = np.load('datasets/val_lbl_64.npy')\n",
    "train_img_small = np.float32(train_img_small) / 255\n",
    "val_img_small = np.float32(val_img_small) / 255\n",
    "print(train_img_small.shape, train_lbl_small.shape)\n",
    "print(val_img_small.shape, val_lbl_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca9b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic data pre-generated by albumentations\n",
    "train_img_synth = np.concatenate([np.load('datasets/train_img_64_synth.npy'), np.load('datasets/train_img_64.npy')], axis=0)\n",
    "train_lbl_synth = np.concatenate([np.load('datasets/train_lbl_64_synth.npy'), np.load('datasets/train_lbl_64.npy')], axis=0)\n",
    "train_img_synth = np.float32(train_img_synth) / 255\n",
    "print(train_img_synth.shape, train_lbl_synth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1df2c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_prob = 0.2\n",
    "spatial_dropout_prob = 0.05\n",
    "reg_coef = 0.01   # experiments suggest this coef might be far too large\n",
    "noise_sigma = 0.04\n",
    "regulator = tf.keras.regularizers.L2(reg_coef)\n",
    "this_model3 = tf.keras.Sequential([ # tf.keras.layers.Rescaling(1. / 255),\n",
    "                                tf.keras.layers.GaussianNoise(noise_sigma),\n",
    "                                    tf.keras.layers.Convolution2D(64, 5, activation='relu', \n",
    "                                                               padding='same', use_bias = True,\n",
    "                                            input_shape = (64,64,3), kernel_regularizer=regulator),\n",
    "                                 tf.keras.layers.Dropout(dropout_prob),\n",
    "                                 tf.keras.layers.SpatialDropout2D(spatial_dropout_prob),\n",
    "                                 tf.keras.layers.Convolution2D(64, 3, activation='relu', \n",
    "                                                               padding='same', use_bias = True,\n",
    "                                                               kernel_regularizer=regulator),\n",
    "                                 tf.keras.layers.MaxPool2D(strides=(2,2)), # default pool size (2,2); cuts down to 32x32xch\n",
    "                                 tf.keras.layers.Convolution2D(128, 3, activation='relu', \n",
    "                                                               padding='same', use_bias = True,\n",
    "                                                              kernel_regularizer=regulator),\n",
    "                                 tf.keras.layers.SpatialDropout2D(spatial_dropout_prob),\n",
    "                                 tf.keras.layers.Dropout(dropout_prob),\n",
    "                                 tf.keras.layers.Convolution2D(128, 3, activation='relu', \n",
    "                                                               padding='same', use_bias = True,\n",
    "                                                              kernel_regularizer=regulator),\n",
    "                                 tf.keras.layers.MaxPool2D(strides=(2,2)), # cuts down to 16x16xch\n",
    "                                 tf.keras.layers.Convolution2D(128, 3, activation='relu', \n",
    "                                                               padding='same', use_bias = True,\n",
    "                                                              kernel_regularizer=regulator),\n",
    "                                 tf.keras.layers.SpatialDropout2D(spatial_dropout_prob),\n",
    "                                 tf.keras.layers.Dropout(dropout_prob),\n",
    "                                 tf.keras.layers.Convolution2D(128, 3, activation='relu', \n",
    "                                                               padding='same', use_bias = True,\n",
    "                                                              kernel_regularizer=regulator),\n",
    "                                 tf.keras.layers.MaxPool2D(strides=(2,2)), # cuts down to 8x8xch\n",
    "                                 tf.keras.layers.Flatten(), # 8192 outputs coming here\n",
    "                                 tf.keras.layers.Dense(512, activation='relu'),\n",
    "                                 tf.keras.layers.Dropout(dropout_prob),\n",
    "                                 tf.keras.layers.Dense(50, activation='softmax')])\n",
    "                                 \n",
    "this_model3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e0f54b",
   "metadata": {},
   "source": [
    "Results: On greyscale, 0.58 val (0.81 tr) after 11 epoch. Compare 0.718 val (0.899 tr) after 19 epochs, back on colour; with dropout 0.2, reg 0.01. Regressed with dropout 0.3, reg 0.02, with 0.65 val (0.81 tr) after 17 epochs. With 64/128/256 filters, 0.72 val (0.92 tr) after 18 epochs. With 3 layers in blocks 2 and 3 (back at 64/128/128), 0.675 (0.86) after 14 epochs. With Scharr filters in input channels, 0.66 (0.87) after 14 epochs.\n",
    "\n",
    "Moving from tanh to relu got us to 0.767 (0.95) after 19 epochs. Added GaussianNoise(0.1) and replaced Dropout with SpatialDropout(0.1). Ended at 0.658 (0.853) after 18 epochs. At this point I realised some the image set hadn't been standardised (as RGB). So I tried that again with SpatialDropout turned down to 0.05. Tried some synthetic data, things got worse. Back up some... take out all but L^2 reg, get 0.614 (0.930) after 8 epochs.\n",
    "\n",
    "Since we still get high scores on the training set it appears the network is expressive enough (at blocks of 2, with 64/128/128 filters) to handle most of that, and getting this generalisation difference down is what we need.\n",
    "\n",
    "So, 0.65 (0.93) after 14 epochs, with regular dropout. Next try, reintroduce gaussian noise at sigma=0.04; got 0.536 (0.88) at epoch 16. Add Dense(512) before the end; got 0.58 (0.95) at epoch 20. Return SpatialDropout, got 0.582 (0.95). Adding some synthetics, 0.608 (0.956)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "089c8fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 1192s 693ms/step - loss: 0.7291 - accuracy: 0.8630 - val_loss: 2.3349 - val_accuracy: 0.5951\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 1207s 702ms/step - loss: 0.6071 - accuracy: 0.8908 - val_loss: 2.2947 - val_accuracy: 0.6001\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 1195s 695ms/step - loss: 0.5447 - accuracy: 0.9089 - val_loss: 2.4485 - val_accuracy: 0.5882\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 1185s 689ms/step - loss: 0.4996 - accuracy: 0.9198 - val_loss: 2.7177 - val_accuracy: 0.5885\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 1179s 686ms/step - loss: 0.4688 - accuracy: 0.9274 - val_loss: 2.7426 - val_accuracy: 0.5899\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 1185s 689ms/step - loss: 0.4417 - accuracy: 0.9339 - val_loss: 2.5915 - val_accuracy: 0.6083\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 1180s 687ms/step - loss: 0.4213 - accuracy: 0.9404 - val_loss: 2.6203 - val_accuracy: 0.6040\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 1192s 693ms/step - loss: 0.3986 - accuracy: 0.9467 - val_loss: 2.8306 - val_accuracy: 0.6041\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 1197s 696ms/step - loss: 0.3841 - accuracy: 0.9496 - val_loss: 2.7694 - val_accuracy: 0.6073\n",
      "Epoch 10/20\n",
      " 844/1719 [=============>................] - ETA: 10:23 - loss: 0.3641 - accuracy: 0.9562"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mthis_model3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_img_synth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_lbl_synth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_img_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_lbl_small\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "this_model3.fit(train_img_synth, train_lbl_synth, validation_data=(val_img_small,val_lbl_small), epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aa11d4",
   "metadata": {},
   "source": [
    "<b>Second pass</b>: The next model is a test of making a skip (\"residual\") connection in the network. The output of the first layer of each block becomes part of the output of the next layer. Since my blocks only have 2 layers in them this involves shrinking the output to match the size at the next block. Results were not encouraging, but I didn't try for too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "664ee39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testSkipModel(tf.keras.Model):\n",
    "    def __init__(self, labels, filters, rec_field, dropout_prob = 0.2, reg_coef = 0.001):\n",
    "        super(testSkipModel, self).__init__()\n",
    "        filters_1, filters_2, filters_3 = filters\n",
    "        regulator = tf.keras.regularizers.L2(reg_coef)\n",
    "\n",
    "        self.conv_1a = tf.keras.layers.Convolution2D(filters_1, 5, padding='same', use_bias=True, \n",
    "                                                     activation='tanh', kernel_regularizer=regulator)\n",
    "        self.conv_1b = tf.keras.layers.Convolution2D(filters_1, 3, padding='same', use_bias=True, \n",
    "                                                     activation='tanh', kernel_regularizer=regulator)\n",
    "    \n",
    "        self.conv_2a = tf.keras.layers.Convolution2D(filters_2, 3, padding='same', use_bias=True, \n",
    "                                                     activation='tanh', kernel_regularizer=regulator)\n",
    "        self.conv_2b = tf.keras.layers.Convolution2D(filters_2, 3, padding='same', use_bias=True, \n",
    "                                                     activation='tanh', kernel_regularizer=regulator)\n",
    "        \n",
    "        self.conv_3a = tf.keras.layers.Convolution2D(filters_3, 3, padding='same', use_bias=True, \n",
    "                                                     activation='tanh', kernel_regularizer=regulator)\n",
    "        self.conv_3b = tf.keras.layers.Convolution2D(filters_3, 3, padding='same', use_bias=True, \n",
    "                                                     activation='tanh', kernel_regularizer=regulator)\n",
    "        \n",
    "        self.collate = tf.keras.layers.Dense(labels, kernel_regularizer=regulator, activation='softmax')\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        #out = tf.keras.layers.Rescaling(1. / 255)(input_tensor)\n",
    "        out = tf.keras.layers.Dropout(0.2)(self.conv_1a(input_tensor))\n",
    "        out_temp = tf.keras.layers.MaxPool2D(strides=(2,2))(out)\n",
    "        out = tf.keras.layers.MaxPool2D(strides=(2,2))(self.conv_1b(out))\n",
    "        \n",
    "        out = tf.raw_ops.Concat(concat_dim=3, values=[out, out_temp]) # skip connection from 1a\n",
    "        out = tf.keras.layers.Dropout(0.2)(self.conv_2a(out))\n",
    "        out_temp = tf.keras.layers.MaxPool2D(strides=(2,2))(out)\n",
    "        out = tf.keras.layers.MaxPool2D(strides=(2,2))(self.conv_2b(out))\n",
    "        \n",
    "        out = tf.raw_ops.Concat(concat_dim=3, values=[out, out_temp]) # skip connection from 2a\n",
    "        out = tf.keras.layers.Dropout(0.2)(self.conv_3a(out))\n",
    "        out_temp = tf.keras.layers.MaxPool2D(strides=(2,2))(out)\n",
    "        out = tf.keras.layers.MaxPool2D(strides=(2,2))(self.conv_3b(out))\n",
    "        \n",
    "        out = tf.raw_ops.Concat(concat_dim=3, values=[out, out_temp]) # skip connection from 3a        \n",
    "        out = tf.keras.layers.Flatten()(out)\n",
    "        out = self.collate(out)\n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11c98846",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSkipper = testSkipModel(50, (64,128,128),3)\n",
    "testSkipper.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7a3bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSkipper.fit(train_img_small, train_lbl_small, validation_data=(val_img_small, val_lbl_small), epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a0278e",
   "metadata": {},
   "source": [
    "<b>Third pass</b>: At this point I started experiments with the \"hand geometry\" output of the MediaPipe detector, which places its 21 landmarks in space. Curiously, the detector has a bit of trouble with my working dataset, only detecting a hand in about 80% of it. I do know that the detector is sensitive to colour: swapping blue/red channels will lead to non-detection. Likewise greyscale is a problem. These are not the conditions it was trained for, apparently.\n",
    "\n",
    "Where the hand landmark data is available, it's enough alone for better results than the short CNNs I tried before. (The landmark data was previously normalised in position, orientation, and chirality.) The best score I got was 0.867 val_acc (0.94 train), with three dense layers of 256/256/256 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "67ffa895",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_geom = np.load(\"datasets/train_geom.npy\")\n",
    "train_lbl = np.load(\"datasets/train_geom_lbl.npy\")\n",
    "val_geom = np.load(\"datasets/val_geom.npy\")\n",
    "val_lbl = np.load(\"datasets/val_geom_lbl.npy\")\n",
    "train_geom = train_geom.reshape((train_geom.shape[0],63))\n",
    "val_geom = val_geom.reshape((val_geom.shape[0], 63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "800e6690",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_prob = 0.2\n",
    "reg_coef = 0.0001\n",
    "regulator = tf.keras.regularizers.L2(reg_coef)\n",
    "rng = np.random.default_rng()\n",
    "layers = 4\n",
    "seeds = [rng.integers(0,1024) for j in range(layers)]\n",
    "inits = [tf.keras.initializers.Orthogonal(seeds[j]) for j in range(layers)]\n",
    "\n",
    "geomModel = tf.keras.models.Sequential([#tf.keras.layers.Flatten(),\n",
    "                                       tf.keras.layers.Dense(256, activation='tanh', \n",
    "                                                             #kernel_initializer = inits[0],\n",
    "                                                             kernel_regularizer=regulator),\n",
    "                                        #tf.keras.layers.Dropout(dropout_prob),\n",
    "                                       tf.keras.layers.Dense(256, activation='tanh', \n",
    "                                                             #kernel_initializer = inits[1],\n",
    "                                                             kernel_regularizer=regulator),\n",
    "                                        #tf.keras.layers.Dropout(dropout_prob),\n",
    "                                       tf.keras.layers.Dense(256, activation='tanh', \n",
    "                                                             #kernel_initializer = inits[2],\n",
    "                                                             kernel_regularizer=regulator),\n",
    "                                        #tf.keras.layers.Dropout(0.5),\n",
    "                                       tf.keras.layers.Dense(50, activation='softmax', \n",
    "                                                             #kernel_initializer = inits[3],\n",
    "                                                             kernel_regularizer=regulator)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069edb41",
   "metadata": {},
   "source": [
    "I looked into tensorflow's options for weight initialisation. Almost all of them are random initialisers, with various distributions (uniform or normal) and variances (people have looked at different normalisations in the quest to make training networks more tractable). The exception is the orthogonal initialiser, which essentially generates a random matrix like the others and then performs Gram-Schmidt/singular value decomposition on it to give an orthogonal matrix of weights.\n",
    "\n",
    "In terms of val_acc achieved, orthogonal initialisation did not yield improvement. It did yield a puzzle: although its accuracy scores are very close to the ordinary random initialisers given like amounts of training time, the reported cross-entropy loss was much higher, by a factor of tens of thousands. (In principle there is no upper-limit to the cross-entropy, the model simply needs to give high enough confidence to a particular wrong answer.) Curious, I tried letting it run for a long time, hundreds of epochs (with the network small enough that this was a matter of minutes rather than days). The cross-entropy does eventually come down, but the accuracy does nothing special. This sort of behaviour makes me think there must be interesting things to say about (for lack of a better expression) the dynamics of NN learning, but I don't know what they might be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01f72c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.0001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                    learning_rate,\n",
    "                    decay_steps=20000,\n",
    "                    decay_rate=0.9,\n",
    "                    staircase=True)\n",
    "\n",
    "geomModel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cdbf059f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "699/699 [==============================] - 3s 5ms/step - loss: 51351.5000 - accuracy: 0.8723 - val_loss: 51276.8594 - val_accuracy: 0.7334\n",
      "Epoch 2/10\n",
      "699/699 [==============================] - 3s 5ms/step - loss: 51201.8164 - accuracy: 0.8730 - val_loss: 51127.4414 - val_accuracy: 0.7340\n",
      "Epoch 3/10\n",
      "699/699 [==============================] - 3s 4ms/step - loss: 51052.5977 - accuracy: 0.8752 - val_loss: 50978.5000 - val_accuracy: 0.7325\n",
      "Epoch 4/10\n",
      "699/699 [==============================] - 3s 4ms/step - loss: 50903.8633 - accuracy: 0.8795 - val_loss: 50829.9180 - val_accuracy: 0.7329\n",
      "Epoch 5/10\n",
      "699/699 [==============================] - 3s 4ms/step - loss: 50755.3398 - accuracy: 0.8802 - val_loss: 50681.5039 - val_accuracy: 0.7358\n",
      "Epoch 6/10\n",
      "699/699 [==============================] - 3s 4ms/step - loss: 50607.0312 - accuracy: 0.8841 - val_loss: 50533.2617 - val_accuracy: 0.7397\n",
      "Epoch 7/10\n",
      "699/699 [==============================] - 3s 5ms/step - loss: 50458.9336 - accuracy: 0.8838 - val_loss: 50385.3516 - val_accuracy: 0.7399\n",
      "Epoch 8/10\n",
      "699/699 [==============================] - 3s 5ms/step - loss: 50311.2852 - accuracy: 0.8846 - val_loss: 50237.9062 - val_accuracy: 0.7375\n",
      "Epoch 9/10\n",
      "699/699 [==============================] - 3s 4ms/step - loss: 50164.9766 - accuracy: 0.8860 - val_loss: 50096.0117 - val_accuracy: 0.7365\n",
      "Epoch 10/10\n",
      "699/699 [==============================] - 3s 4ms/step - loss: 50028.9102 - accuracy: 0.8872 - val_loss: 49962.5898 - val_accuracy: 0.7384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea6e230340>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geomModel.fit(train_geom, train_lbl, validation_data=(val_geom, val_lbl), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50641f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for j in range(0, epochs):\n",
    "    geomModel.fit(train_geom, train_lbl, epochs=1)\n",
    "    geomModel.evaluate(val_geom, val_lbl, verbose=2)\n",
    "# 200 epochs later... \"you haven't converged or blown up yet? another round! Adam, what a dogged searcher.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6866567",
   "metadata": {},
   "source": [
    "<b>Fourth pass</b>: models combining image and geometric data. I'm looking at an attention-type mechanism where a short network uses the geometry to make weights for the convolutional network. Since the geometric data isn't there for every frame it also tries to train a 'back-up' layer just from the image data. It works better than previous tries. There's still a lot I don't know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d56bb67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26573, 21, 3) (5958, 21, 3)\n"
     ]
    }
   ],
   "source": [
    "train_geom_full = np.load(\"datasets/train_geom_full.npy\")\n",
    "val_geom_full = np.load(\"datasets/val_geom_full.npy\")\n",
    "print(train_geom_full.shape, val_geom_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "fe913ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_geom_full = train_geom_full.reshape((train_geom_full.shape[0], 63))\n",
    "val_geom_full = val_geom_full.reshape((val_geom_full.shape[0],63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "f89b62fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26573, 64, 64, 3) (5958, 64, 64, 3)\n",
      "(26573,) (5958,)\n"
     ]
    }
   ],
   "source": [
    "train_img_small = np.load('datasets/train_img_64.npy')\n",
    "train_lbl_small = np.load('datasets/train_lbl_64.npy')\n",
    "val_img_small = np.load('datasets/val_img_64.npy')\n",
    "val_lbl_small = np.load('datasets/val_lbl_64.npy')\n",
    "print(train_img_small.shape, val_img_small.shape)\n",
    "print(train_lbl_small.shape, val_lbl_small.shape)\n",
    "train_img_small = np.float32(train_img_small) / 255\n",
    "val_img_small = np.float32(val_img_small) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc778c3a",
   "metadata": {},
   "source": [
    "Tensorboard is a profiling add-on. it can tell you lots of things about the statistics of your model's weights,\n",
    "how much time it takes doing what operations, and a lot more. I've barely taken a look.\n",
    "\n",
    "https://www.tensorflow.org/tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f2ee4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a5b65e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = '2000,2010')\n",
    "# the data it logs can take up a lot of space, so they recommend using it only for 10 or 20 steps to gather its statistics,\n",
    "# and not steps at the beginning, where there can be overhead etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a2a8e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a1c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularisation stuff...\n",
    "# tf.keras.layers.GaussianNoise(noise_sigma) (last used sigma = 0.04)\n",
    "# tf.keras.regularizers.L2(reg_coef) (last used coef 0.001 or 0.0001?)\n",
    "# tf.keras.layers.Dropout(dropout_prob) (last used prob = 0.2)\n",
    "# tf.keras.layers.SpatialDropout2D(spatial_dropout_prob) (last used prob = 0.05)\n",
    "\n",
    "# Augmentation stuff -- when using gpu it's advised to stick this on the dataset; as long as the preprocessing\n",
    "# consists only of tensorflow Graph-able operations it'll be executed in parallel when data is about to be called from it\n",
    "\n",
    "# train_img_tf = tf.data.Dataset.from_tensor_slices(train_img_small)\n",
    "# train_img_tf.map(lambda x: pre_process(x)), where pre_process could be a keras.Sequential object\n",
    "\n",
    "# tf.keras.layers.RandomBrightness(factor, value_range=(0, 1)) (factor = pair of floats in [-1,1])\n",
    "# tf.keras.layers.RandomContrast(factor in [0,1])\n",
    "# tf.keras.layers.RandomFlip(mode='horizontal')\n",
    "# tf.keras.layers.RandomRotation(fill_mode='constant', factor in [0,1]), rotation up to angle factor*2pi\n",
    "# tf.keras.layers.RandomZoom(height_factor=0.2, fill_mode='constant')  default arg width_factor=None preserves aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "c3b926be",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesiser_train = tf.keras.Sequential([tf.keras.layers.RandomBrightness(0.15, value_range=(0,1)),\n",
    "                                    tf.keras.layers.RandomFlip(mode = 'horizontal'),\n",
    "                                    tf.keras.layers.RandomRotation(0.04, fill_mode='constant'),\n",
    "                                    tf.keras.layers.RandomZoom(height_factor=0.2, fill_mode='constant')])\n",
    "batch_size = train_img_small.shape[0]\n",
    "train_img_tf = tf.data.Dataset.from_tensor_slices(train_img_small)\n",
    "train_geom_tf = tf.data.Dataset.from_tensor_slices(train_geom_full)\n",
    "\n",
    "# this makes a dataset object with an attached function, rather than just applying a function once to its tensors\n",
    "train_synth = train_img_tf.map(lambda x: synthesiser_train(x),\n",
    "                                 num_parallel_calls=batch_size).batch(batch_size)\n",
    "train_proc = train_synth.get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "8cb5a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why two copies of the same object? because tensorflow handles batch size in a way I don't understand, and\n",
    "# using the same one in two places raises errors\n",
    "synthesiser_val = tf.keras.Sequential([tf.keras.layers.RandomBrightness(0.15, value_range=(0,1)),\n",
    "                                    tf.keras.layers.RandomFlip(mode = 'horizontal'),\n",
    "                                    tf.keras.layers.RandomRotation(0.04, fill_mode='constant'),\n",
    "                                    tf.keras.layers.RandomZoom(height_factor=0.2, fill_mode='constant')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "a0da06a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testAttentionModel(tf.keras.Model):\n",
    "    def __init__(self, conv_filters, reg_coef=0, labels=50):\n",
    "        super(testAttentionModel, self).__init__()\n",
    "        filters_1, filters_2, filters_3 = conv_filters\n",
    "        self.reg = tf.keras.regularizers.L2(reg_coef)\n",
    "        conv_out_size = 8*8*filters_3\n",
    "        self.spatial_dropout_prob = 0.02\n",
    "        self.dropout_prob = 0.1\n",
    "        \n",
    "        # 64x64xch\n",
    "        self.conv_1a = tf.keras.layers.Convolution2D(filters_1, 5, padding='same', use_bias=True, \n",
    "                                                     activation='relu',\n",
    "                                                     kernel_regularizer=self.reg)\n",
    "        self.conv_1b = tf.keras.layers.Convolution2D(filters_1, 3, padding='same', use_bias=True, \n",
    "                                                     activation='relu',\n",
    "                                                     kernel_regularizer=self.reg)\n",
    "        # 32x32xch\n",
    "        self.conv_2a = tf.keras.layers.Convolution2D(filters_2, 3, padding='same', use_bias=True, \n",
    "                                                     activation='relu',\n",
    "                                                     kernel_regularizer=self.reg)\n",
    "        self.conv_2b = tf.keras.layers.Convolution2D(filters_2, 3, padding='same', use_bias=True,\n",
    "                                                     activation='relu',\n",
    "                                                     kernel_regularizer=self.reg)\n",
    "        # 16x16xch\n",
    "        self.conv_3a = tf.keras.layers.Convolution2D(filters_3, 3, padding='same', use_bias=True, \n",
    "                                                     activation='relu',\n",
    "                                                    kernel_regularizer=self.reg)\n",
    "        self.conv_3b = tf.keras.layers.Convolution2D(filters_3, 3, padding='same', use_bias=True, \n",
    "                                                     activation='relu',\n",
    "                                                     kernel_regularizer=self.reg)\n",
    "        # 8x8xch\n",
    "        #self.conv_4a = tf.keras.layers.Convolution2D(filters_4, 3, padding='same', use_bias=True, activation='relu')\n",
    "                                                    # activation='tanh', kernel_regularizer=regulator)\n",
    "        #self.conv_4b = tf.keras.layers.Convolution2D(filters_4, 3, padding='same', use_bias=True, activation='relu')\n",
    "                                                     #activation='tanh', kernel_regularizer=regulator)\n",
    "        # out: 4x4xch\n",
    "        \n",
    "        self.geom1 = tf.keras.layers.Dense(64, use_bias=True, activation='relu', kernel_regularizer=self.reg)\n",
    "        self.geom_backup = tf.keras.layers.Dense(64, use_bias=True, activation='relu')\n",
    "        self.geom2 = tf.keras.layers.Dense(conv_out_size, use_bias=True, activation='relu', kernel_regularizer=self.reg)\n",
    "        #self.dense3 = tf.keras.layers.Dense(units_3, use_bias=True, \n",
    "        #                                             activation='tanh', kernel_regularizer=regulator)\n",
    "        self.policy = tf.keras.layers.Dense(labels, activation='softmax')\n",
    "        \n",
    "    def call(self, input_list, training=True):\n",
    "        #input_layer = tf.reshape(input_list[0], [-1, 64, 64, 3])\n",
    "        c_out = tf.keras.layers.GaussianNoise(0.03)(input_list[0], training=training)\n",
    "        c_out = tf.keras.layers.SpatialDropout2D(self.spatial_dropout_prob)(self.conv_1a(c_out),\n",
    "                                                                            training=training)\n",
    "        c_out = tf.keras.layers.MaxPool2D(strides=(2,2))(self.conv_1b(c_out))\n",
    "        c_out = tf.keras.layers.SpatialDropout2D(self.spatial_dropout_prob)(self.conv_2a(c_out),\n",
    "                                                                            training=training)\n",
    "        c_out = tf.keras.layers.MaxPool2D(strides=(2,2))(self.conv_2b(c_out))\n",
    "        c_out = tf.keras.layers.SpatialDropout2D(self.spatial_dropout_prob) (self.conv_3a(c_out),\n",
    "                                                                            training=training)\n",
    "        c_out = tf.keras.layers.MaxPool2D(strides=(2,2))(self.conv_3b(c_out))\n",
    "        #c_out = self.conv_4a(c_out)\n",
    "        #c_out = tf.keras.layers.MaxPool2D(strides=(2,2))(self.conv_4b(c_out))\n",
    "        c_output = tf.keras.layers.Flatten()(c_out)\n",
    "       \n",
    "        g_out = self.geom1(input_list[1])\n",
    "        if tf.math.reduce_max(g_out) == 0:\n",
    "            g_out = self.geom_backup(tf.keras.layers.Flatten()(input_list[0]))\n",
    "        g_out = tf.keras.layers.Dropout(self.dropout_prob)(g_out, training=training)\n",
    "        g_out = tf.keras.layers.Dropout(self.dropout_prob)(self.geom2(g_out),training=training)\n",
    "       \n",
    "        return self.policy(tf.keras.layers.Multiply()([c_output, g_out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "3ec6422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testAttender2 = testAttentionModel((64,128,256), reg_coef=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "9cfdc73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.0001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                    learning_rate,\n",
    "                    decay_steps=5000,\n",
    "                    decay_rate=0.9,\n",
    "                    staircase=True)\n",
    "\n",
    "testAttender2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04caea9f",
   "metadata": {},
   "source": [
    "Results: 0.790 (0.964) with 3 blocks 64/128/256. Reg at 0.001 didn't help, 0.77 (0.966). (At this point cut half of the dataset grass.) Added spatial/regular dropout at 0.04/0.2, reg=0.001. Slower, val stalled around .745 (tr continued up to .93). adding in synth data, tr_acc (on the same model) went down to .745 too. but while it recovered val did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae9d25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "831/831 [==============================] - 643s 769ms/step - loss: 2.1825 - accuracy: 0.5577 - val_loss: 1.9516 - val_accuracy: 0.6015\n",
      "Epoch 2/80\n",
      "831/831 [==============================] - 640s 770ms/step - loss: 1.6063 - accuracy: 0.6559 - val_loss: 1.8304 - val_accuracy: 0.6170\n",
      "Epoch 3/80\n",
      "831/831 [==============================] - 639s 769ms/step - loss: 1.4515 - accuracy: 0.6765 - val_loss: 1.7214 - val_accuracy: 0.6299\n",
      "Epoch 4/80\n",
      "831/831 [==============================] - 651s 783ms/step - loss: 1.3320 - accuracy: 0.7010 - val_loss: 1.6108 - val_accuracy: 0.6482\n",
      "Epoch 5/80\n",
      "831/831 [==============================] - 650s 782ms/step - loss: 1.2167 - accuracy: 0.7218 - val_loss: 1.4926 - val_accuracy: 0.6804\n",
      "Epoch 6/80\n",
      "831/831 [==============================] - 642s 773ms/step - loss: 1.1065 - accuracy: 0.7464 - val_loss: 1.4383 - val_accuracy: 0.6841\n",
      "Epoch 7/80\n",
      "831/831 [==============================] - 632s 761ms/step - loss: 1.0190 - accuracy: 0.7674 - val_loss: 1.3759 - val_accuracy: 0.7017\n",
      "Epoch 8/80\n",
      "831/831 [==============================] - 631s 760ms/step - loss: 0.9500 - accuracy: 0.7823 - val_loss: 1.3145 - val_accuracy: 0.7189\n",
      "Epoch 9/80\n",
      "831/831 [==============================] - 630s 758ms/step - loss: 0.8642 - accuracy: 0.8024 - val_loss: 1.3363 - val_accuracy: 0.7301\n",
      "Epoch 10/80\n",
      "831/831 [==============================] - 642s 772ms/step - loss: 0.8113 - accuracy: 0.8162 - val_loss: 1.2992 - val_accuracy: 0.7415\n",
      "Epoch 11/80\n",
      "831/831 [==============================] - 646s 777ms/step - loss: 0.7548 - accuracy: 0.8298 - val_loss: 1.3843 - val_accuracy: 0.7388\n",
      "Epoch 12/80\n",
      "831/831 [==============================] - 640s 770ms/step - loss: 0.7007 - accuracy: 0.8432 - val_loss: 1.2786 - val_accuracy: 0.7511\n",
      "Epoch 13/80\n",
      "831/831 [==============================] - 642s 773ms/step - loss: 0.6671 - accuracy: 0.8553 - val_loss: 1.3056 - val_accuracy: 0.7550\n",
      "Epoch 14/80\n",
      "831/831 [==============================] - 651s 783ms/step - loss: 0.6121 - accuracy: 0.8668 - val_loss: 1.2869 - val_accuracy: 0.7638\n",
      "Epoch 15/80\n",
      "831/831 [==============================] - 647s 778ms/step - loss: 0.5810 - accuracy: 0.8742 - val_loss: 1.3771 - val_accuracy: 0.7612\n",
      "Epoch 16/80\n",
      "831/831 [==============================] - 643s 773ms/step - loss: 0.5625 - accuracy: 0.8793 - val_loss: 1.2763 - val_accuracy: 0.7692\n",
      "Epoch 17/80\n",
      "831/831 [==============================] - 641s 772ms/step - loss: 0.5321 - accuracy: 0.8888 - val_loss: 1.3131 - val_accuracy: 0.7706\n",
      "Epoch 18/80\n",
      "831/831 [==============================] - 639s 769ms/step - loss: 0.5013 - accuracy: 0.8962 - val_loss: 1.3900 - val_accuracy: 0.7638\n",
      "Epoch 19/80\n",
      "831/831 [==============================] - 638s 768ms/step - loss: 0.4783 - accuracy: 0.9025 - val_loss: 1.4689 - val_accuracy: 0.7627\n",
      "Epoch 20/80\n",
      "831/831 [==============================] - 640s 771ms/step - loss: 0.4586 - accuracy: 0.9086 - val_loss: 1.4423 - val_accuracy: 0.7722\n",
      "Epoch 21/80\n",
      "831/831 [==============================] - 635s 764ms/step - loss: 0.4438 - accuracy: 0.9140 - val_loss: 1.4744 - val_accuracy: 0.7721\n",
      "Epoch 22/80\n",
      "831/831 [==============================] - 639s 769ms/step - loss: 0.4258 - accuracy: 0.9181 - val_loss: 1.5709 - val_accuracy: 0.7754\n",
      "Epoch 23/80\n",
      "831/831 [==============================] - 636s 766ms/step - loss: 0.4089 - accuracy: 0.9220 - val_loss: 1.4678 - val_accuracy: 0.7701\n",
      "Epoch 24/80\n",
      "831/831 [==============================] - 645s 776ms/step - loss: 0.4008 - accuracy: 0.9246 - val_loss: 1.5421 - val_accuracy: 0.7716\n",
      "Epoch 25/80\n",
      "831/831 [==============================] - 651s 783ms/step - loss: 0.3750 - accuracy: 0.9317 - val_loss: 1.6002 - val_accuracy: 0.7753\n",
      "Epoch 26/80\n",
      "831/831 [==============================] - 657s 790ms/step - loss: 0.3567 - accuracy: 0.9364 - val_loss: 1.6084 - val_accuracy: 0.7758\n",
      "Epoch 27/80\n",
      "831/831 [==============================] - 656s 790ms/step - loss: 0.3504 - accuracy: 0.9387 - val_loss: 1.6619 - val_accuracy: 0.7788\n",
      "Epoch 28/80\n",
      "831/831 [==============================] - 661s 795ms/step - loss: 0.3401 - accuracy: 0.9399 - val_loss: 1.7516 - val_accuracy: 0.7746\n",
      "Epoch 29/80\n",
      "831/831 [==============================] - 648s 780ms/step - loss: 0.3346 - accuracy: 0.9413 - val_loss: 1.5752 - val_accuracy: 0.7650\n",
      "Epoch 30/80\n",
      "831/831 [==============================] - 642s 773ms/step - loss: 0.3268 - accuracy: 0.9459 - val_loss: 1.6586 - val_accuracy: 0.7737\n",
      "Epoch 31/80\n",
      "831/831 [==============================] - 658s 792ms/step - loss: 0.3071 - accuracy: 0.9512 - val_loss: 1.8101 - val_accuracy: 0.7843\n",
      "Epoch 32/80\n",
      "831/831 [==============================] - 640s 770ms/step - loss: 0.2968 - accuracy: 0.9523 - val_loss: 1.7552 - val_accuracy: 0.7835\n",
      "Epoch 33/80\n",
      "831/831 [==============================] - 644s 775ms/step - loss: 0.2895 - accuracy: 0.9544 - val_loss: 1.9012 - val_accuracy: 0.7795\n",
      "Epoch 34/80\n",
      "285/831 [=========>....................] - ETA: 6:40 - loss: 0.2850 - accuracy: 0.9575"
     ]
    }
   ],
   "source": [
    "testAttender2.fit([train_proc, train_geom_full], train_lbl_small,\n",
    "                 validation_data=([val_img_small, val_geom_full], val_lbl_small),\n",
    "                 epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9973747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model tries out test-time data augmentation; that is, given an image it generates some random synthetic frames \n",
    "# from it, gives those to the underlying trained model, and returns their averaged probabilities\n",
    "class testPollModel(tf.keras.Model):\n",
    "    def __init__(self, polled_model, size):\n",
    "        super(testPollModel, self).__init__()\n",
    "        self.size = size\n",
    "        self.polled_model = polled_model\n",
    "        \n",
    "    def call(self, input_list):\n",
    "        vote_list = []\n",
    "        for j in range(self.size):\n",
    "            vote_list.append(self.polled_model(input_list = [synthesiser_val(input_list[0]), input_list[1]], \n",
    "                                               training=False))\n",
    "        return tf.keras.layers.Average()(vote_list)\n",
    "# I'm uncertain whether this is computationally the most efficient route. tensorflow does a lot of automatic optimisation\n",
    "# (I've learned) but there's something here it really doesn't like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e29040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4faae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
